{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe Withdrawal Rate Analysis: MSCI World 70% + BTP 10Y 30% (No Tax)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook performs a **Monte Carlo simulation** using **block bootstrap** methodology to analyze the **Safe Withdrawal Rate (SWR)** for a portfolio composed of:\n",
    "- **70% MSCI World Index (Net Total Return)** (global equities)\n",
    "- **30% Italian BTP 10Y** (government bonds)\n",
    "\n",
    "> ⚠️ **Tax Assumption**: This simulation assumes **no capital gains tax** is applied on withdrawals. This represents an idealized scenario (e.g., tax-advantaged accounts, jurisdictions with no capital gains tax, or assets held beyond tax-exemption thresholds). For a realistic analysis in taxed environments, withdrawal amounts should be grossed up to account for applicable taxes.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Block Bootstrap Approach\n",
    "Unlike traditional Monte Carlo simulations that assume independent returns, the **block bootstrap** preserves the temporal structure and correlations in financial data by:\n",
    "1. Sampling **consecutive blocks** of historical data (default: 6 months)\n",
    "2. Randomly concatenating these blocks to create simulated future scenarios\n",
    "3. Maintaining serial correlation and regime persistence\n",
    "\n",
    "### Key Features\n",
    "- **Historical data**: Daily returns from 2000-2025 (MSCI World) and 1997-2025 (BTP)\n",
    "- **Inflation adjustment**: Withdrawals adjusted using Euro area HICP inflation\n",
    "- **Calendar days**: All calculations use 365 days/year (not trading days)\n",
    "- **100,000 simulations**: Provides robust statistical estimates\n",
    "- **30-year horizon**: Standard retirement planning period\n",
    "- **No capital gains tax**: Withdrawals are not subject to any taxation\n",
    "\n",
    "### What This Analysis Provides\n",
    "1. **Success rate**: Probability that portfolio survives 30 years\n",
    "2. **Portfolio evolution**: Percentile bands (5th, 25th, 50th, 75th, 95th)\n",
    "3. **Sensitivity analysis**: Impact of different withdrawal rates (2%-5%)\n",
    "4. **Failure analysis**: Distribution of depletion years for failed scenarios\n",
    "\n",
    "### Data Sources\n",
    "- **Equities**: MSCI World Net Total Return Index (EUR) - includes reinvested dividends net of withholding taxes\n",
    "- **Bonds**: Italian BTP 10Y yields (converted to returns)\n",
    "- **Inflation**: Eurostat HICP for Euro area\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Data Loading Functions\n",
    "\n",
    "These functions load historical price data for:\n",
    "- **Equity indices**: MSCI World (Net Total Return), MSCI ACWI, MSCI Italy, STOXX Europe 600\n",
    "- **Bond yields**: BTP 10Y (Italy), OAT 10Y (France)\n",
    "- **Inflation**: ISTAT FOI (Italy), Eurostat HICP (Italy & Euro area)\n",
    "\n",
    "> **Note on MSCI indices**: All MSCI indices used are **Net Total Return** versions, which include reinvested dividends after deducting withholding taxes applicable to non-resident investors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_asset_data(base_path: Path) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load all asset data from CSV files.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with asset names as keys and DataFrames as values\n",
    "    \"\"\"\n",
    "    assets = {}\n",
    "    \n",
    "    # MSCI indices\n",
    "    msci_files = {\n",
    "        'MSCI_WORLD': 'data/msci/WORLD.csv',\n",
    "        'MSCI_ACWI': 'data/msci/ACWI.csv',\n",
    "        'MSCI_ITALY': 'data/msci/ITALY.csv'\n",
    "    }\n",
    "    \n",
    "    for name, path in msci_files.items():\n",
    "        df = pd.read_csv(base_path / path)\n",
    "        df.columns = ['date', 'price']\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('date')\n",
    "        assets[name] = df\n",
    "    \n",
    "    # STOXX\n",
    "    df_stoxx = pd.read_csv(base_path / 'data/stoxx/STOXX_SXXGR_DAILY.csv')\n",
    "    df_stoxx.columns = ['date', 'price']\n",
    "    df_stoxx['date'] = pd.to_datetime(df_stoxx['date'])\n",
    "    df_stoxx = df_stoxx.sort_values('date')\n",
    "    assets['STOXX_SXXGR'] = df_stoxx\n",
    "    \n",
    "    # BTP 10Y (Italian bonds)\n",
    "    df_btp = pd.read_csv(base_path / 'data/bdi/BMK0200/MFN_BMK.D.020.922.0.EUR.210.csv')\n",
    "    df_btp.columns = ['date', 'yield']\n",
    "    df_btp['date'] = pd.to_datetime(df_btp['date'])\n",
    "    df_btp = df_btp.sort_values('date')\n",
    "    assets['BTP_10Y'] = df_btp\n",
    "    \n",
    "    # OAT 10Y (French bonds)\n",
    "    df_oat = pd.read_csv(base_path / 'data/oat/FRANCE_10_YEARS_DAILY_YIELDS_MERGED_FR10.csv')\n",
    "    df_oat.columns = ['date', 'yield']\n",
    "    df_oat['date'] = pd.to_datetime(df_oat['date'])\n",
    "    df_oat = df_oat.sort_values('date')\n",
    "    assets['OAT_10Y'] = df_oat\n",
    "    \n",
    "    return assets\n",
    "\n",
    "\n",
    "def load_inflation_data(base_path: Path) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load inflation data from CSV files.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with inflation series names as keys and DataFrames as values\n",
    "    \"\"\"\n",
    "    inflation = {}\n",
    "    \n",
    "    # ISTAT FOI (Italy)\n",
    "    df_foi = pd.read_csv(base_path / 'data/istat/FOI_MONTHLY.csv')\n",
    "    df_foi.columns = ['date', 'value', 'base']\n",
    "    df_foi['date'] = pd.to_datetime(df_foi['date'])\n",
    "    df_foi = df_foi.sort_values('date')\n",
    "    inflation['FOI_IT'] = df_foi[['date', 'value']]\n",
    "    \n",
    "    # Eurostat HICP\n",
    "    df_hicp = pd.read_csv(base_path / 'data/eurostat/hicp_it_eu.csv')\n",
    "    df_hicp['TIME_PERIOD'] = pd.to_datetime(df_hicp['TIME_PERIOD'])\n",
    "    \n",
    "    # Filter for Italy and EU\n",
    "    df_hicp_it = df_hicp[df_hicp['geo'] == 'Italy'][['TIME_PERIOD', 'OBS_VALUE']].copy()\n",
    "    df_hicp_it.columns = ['date', 'value']\n",
    "    df_hicp_it = df_hicp_it.sort_values('date')\n",
    "    inflation['HICP_IT'] = df_hicp_it\n",
    "    \n",
    "    df_hicp_eu = df_hicp[df_hicp['geo'] == 'Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)'][['TIME_PERIOD', 'OBS_VALUE']].copy()\n",
    "    df_hicp_eu.columns = ['date', 'value']\n",
    "    df_hicp_eu = df_hicp_eu.sort_values('date')\n",
    "    inflation['HICP_EU'] = df_hicp_eu\n",
    "    \n",
    "    return inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation Functions\n",
    "\n",
    "### Return Calculations\n",
    "- **Equity returns**: Log returns calculated as `ln(P_t / P_{t-1})`\n",
    "- **Bond returns**: \n",
    "  - **Total return approximation**: `yield_t/365 - duration × Δyield_t` (simple return)\n",
    "  - **Then converted to log return**: `ln(1 + simple_return)`\n",
    "  - Captures both income (yield) and capital gain/loss (duration × yield change)\n",
    "  - Uses modified duration ≈ 8.0 for 10Y bonds\n",
    "- **Inflation**: Log returns calculated as `ln(CPI_t / CPI_{t-1})`\n",
    "\n",
    "### Consistency Note\n",
    "All returns are expressed as LOG RETURNS. This ensures:\n",
    "1. Correct weighted averaging for portfolio returns\n",
    "2. Correct compounding via `exp(sum(log_returns)) - 1`\n",
    "3. Mathematical consistency across all asset classes\n",
    "\n",
    "### Bond Total Return Model\n",
    "The total return of a bond consists of two components:\n",
    "1. **Income return**: The yield earned over the holding period (`yield / 365` per day)\n",
    "2. **Price return**: Capital gain/loss due to yield changes (`-duration × Δyield`)\n",
    "\n",
    "This is a **linear approximation** valid for small yield changes. Limitations:\n",
    "- Ignores convexity (second-order effects)\n",
    "- Assumes constant duration (actual duration changes with yield levels)\n",
    "- For higher precision, use official total return indices\n",
    "\n",
    "### Key Notes\n",
    "- All data uses **calendar days** (365 days/year), not trading days (252 days/year)\n",
    "- Monthly inflation is divided by actual days in month for precision\n",
    "- Forward-fill is used to handle missing data (weekends, holidays)\n",
    "- All returns (equity, bond, inflation) use log returns for consistent compounding via `exp(sum(log_returns)) - 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_returns(df: pd.DataFrame, price_col: str = 'price') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate daily log returns from price data.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['return'] = np.log(df[price_col] / df[price_col].shift(1))\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def calculate_bond_returns_income_only(df: pd.DataFrame, yield_col: str = 'yield') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate daily returns from bond yields using INCOME ONLY (old method).\n",
    "    \n",
    "    This method is DEPRECATED - it ignores capital gains/losses from yield changes.\n",
    "    Kept for comparison purposes.\n",
    "    \n",
    "    Daily return ≈ yield/365 (income return only)\n",
    "    \n",
    "    WARNING: This significantly underestimates volatility and misses capital\n",
    "    gains during falling rate environments and capital losses during rising rates.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['return'] = df[yield_col] / 100 / 365  # Simple daily yield return (calendar days)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_bond_total_returns(\n",
    "    df: pd.DataFrame,\n",
    "    yield_col: str = 'yield',\n",
    "    duration: float = 8.0,\n",
    "    yield_in_percent: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate daily TOTAL returns from bond yields using duration approximation.\n",
    "    \n",
    "    Returns LOG RETURNS for consistency with equity calculations and \n",
    "    the simulation's compounding method: exp(sum(log_returns)) - 1\n",
    "    \n",
    "    Total Return (simple) ≈ (yield_t / 365) - duration × Δyield_t\n",
    "    Then converted to log return: ln(1 + simple_return)\n",
    "    \n",
    "    This captures both:\n",
    "    1. Income return: yield earned over the holding period\n",
    "    2. Price return: capital gain/loss due to yield changes (via duration)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with date and yield columns\n",
    "        yield_col: Name of the yield column\n",
    "        duration: Modified duration of the bond (default 8.0 for 10Y bonds)\n",
    "        yield_in_percent: True if yields are in percent format (e.g., 2.5 for 2.5%)\n",
    "                         False if yields are in decimal format (e.g., 0.025 for 2.5%)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with 'date' and 'return' columns (LOG RETURNS, first row dropped due to diff)\n",
    "    \n",
    "    Notes:\n",
    "        - This is a LINEAR APPROXIMATION valid for small yield changes\n",
    "        - Ignores convexity (second-order effects on price)\n",
    "        - Assumes constant duration (actual duration varies with yield level)\n",
    "        - For higher precision, use official total return indices (e.g., Bloomberg indices)\n",
    "        - Modified duration for a 10Y bond is typically 7-9 depending on coupon and yield\n",
    "    \n",
    "    Example:\n",
    "        If yield drops from 2.5% to 2.4% (Δyield = -0.001 or -10 bps):\n",
    "        - Income return: 0.025 / 365 ≈ 0.0068% per day\n",
    "        - Price return: -8.0 × (-0.001) = +0.8%\n",
    "        - Total simple return ≈ +0.81% for that day\n",
    "        - Log return: ln(1 + 0.0081) ≈ 0.0081\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert yield to decimal if in percent format\n",
    "    if yield_in_percent:\n",
    "        yield_decimal = df[yield_col] / 100\n",
    "    else:\n",
    "        yield_decimal = df[yield_col]\n",
    "    \n",
    "    # Calculate yield change (Δyield)\n",
    "    yield_change = yield_decimal.diff()\n",
    "    \n",
    "    # Calculate total return components (as simple returns)\n",
    "    income_return = yield_decimal / 365\n",
    "    price_return = -duration * yield_change\n",
    "    simple_return = income_return + price_return\n",
    "    \n",
    "    # Convert to LOG RETURN for consistency with equity returns\n",
    "    # Add floor to handle extreme negative returns (prevents log of negative number)\n",
    "    # Floor at -99.9% simple return (very conservative, allows for extreme but realistic scenarios)\n",
    "    simple_return_floored = np.maximum(simple_return, -0.999)\n",
    "    df['return'] = np.log(1 + simple_return_floored)\n",
    "    \n",
    "    # Drop first row (NaN from diff) and any other missing values\n",
    "    df = df.dropna(subset=['return'])\n",
    "    df = df[['date', 'return']].copy()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Legacy alias for backward compatibility (points to old income-only method)\n",
    "calculate_bond_returns = calculate_bond_returns_income_only\n",
    "\n",
    "\n",
    "def calculate_inflation_rate(df: pd.DataFrame, value_col: str = 'value') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate monthly inflation rate from price index using LOG RETURNS.\n",
    "    \n",
    "    Using log returns ensures consistency with:\n",
    "    - Equity return calculations (also log returns)\n",
    "    - The compounding method in simulations: exp(sum(log_returns)) - 1\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with date and price index columns\n",
    "        value_col: Name of the price index column\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with 'date' and 'inflation' columns (log returns)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['inflation'] = np.log(df[value_col] / df[value_col].shift(1))\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def merge_to_common_dates(assets_dict: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge all asset returns to common dates.\n",
    "    \"\"\"\n",
    "    merged = None\n",
    "    \n",
    "    for name, df in assets_dict.items():\n",
    "        df_temp = df[['date', 'return']].copy()\n",
    "        df_temp.columns = ['date', name]\n",
    "        \n",
    "        if merged is None:\n",
    "            merged = df_temp\n",
    "        else:\n",
    "            merged = pd.merge(merged, df_temp, on='date', how='outer')\n",
    "    \n",
    "    merged = merged.sort_values('date')\n",
    "    return merged\n",
    "\n",
    "def calculate_portfolio_log_return(\n",
    "    returns_df: pd.DataFrame,\n",
    "    weights: Dict[str, float]\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate portfolio log return from individual asset log returns.\n",
    "    \n",
    "    Log returns are NOT additive cross-sectionally (across assets).\n",
    "    They are only additive temporally (same asset over time).\n",
    "    \n",
    "    Correct formula: r_portfolio = ln(sum(w_i * exp(r_i)))\n",
    "    \n",
    "    This converts log returns to growth factors, takes weighted average,\n",
    "    then converts back to log return.\n",
    "    \n",
    "    Args:\n",
    "        returns_df: DataFrame with columns for each asset (log returns)\n",
    "        weights: Dictionary {asset_name: weight} where weights sum to 1\n",
    "        \n",
    "    Returns:\n",
    "        Series with portfolio log returns\n",
    "    \"\"\"\n",
    "    # Calculate weighted sum of growth factors: sum(w_i * exp(r_i))\n",
    "    weighted_growth = sum(\n",
    "        weights[asset] * np.exp(returns_df[asset])\n",
    "        for asset in weights.keys()\n",
    "    )\n",
    "    \n",
    "    # Convert back to log return\n",
    "    return np.log(weighted_growth)\n",
    "\n",
    "def upsample_inflation_to_daily(inflation_df: pd.DataFrame, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert monthly inflation to daily by dividing by days in month.\n",
    "    \"\"\"\n",
    "    daily_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    daily_df = pd.DataFrame({'date': daily_dates})\n",
    "    \n",
    "    # Create year-month column for merging\n",
    "    daily_df['year_month'] = daily_df['date'].dt.to_period('M')\n",
    "    daily_df['days_in_month'] = daily_df['date'].dt.days_in_month\n",
    "    \n",
    "    inflation_df = inflation_df.copy()\n",
    "    inflation_df['year_month'] = inflation_df['date'].dt.to_period('M')\n",
    "    \n",
    "    # Merge\n",
    "    merged = pd.merge(daily_df, inflation_df[['year_month', 'inflation']], \n",
    "                      on='year_month', how='left')\n",
    "    \n",
    "    # Convert monthly to daily (divide by actual days in month)\n",
    "    merged['daily_inflation'] = merged['inflation'] / merged['days_in_month']\n",
    "    merged = merged[['date', 'daily_inflation']]\n",
    "    merged.columns = ['date', 'inflation']\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Block Bootstrap Implementation\n",
    "\n",
    "### Why Block Bootstrap?\n",
    "Financial returns exhibit:\n",
    "- **Volatility clustering**: High/low volatility periods persist\n",
    "- **Serial correlation**: Today's return affects tomorrow's\n",
    "- **Market regimes**: Bull/bear markets last for extended periods\n",
    "\n",
    "### How It Works\n",
    "1. Divide historical data into overlapping blocks (default: 6 months = ~180 days)\n",
    "2. Randomly sample blocks with replacement\n",
    "3. Concatenate to create 30 years (10,950 days) of simulated returns\n",
    "4. Preserve within-block correlations and patterns\n",
    "\n",
    "### Block Size Parameter\n",
    "- **Smaller blocks** (1-3 months): More independent, less structure preservation\n",
    "- **Larger blocks** (6-12 months): Better structure preservation, less variation\n",
    "- **Default**: 6 months balances both objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_bootstrap_sample(\n",
    "    data: pd.DataFrame,\n",
    "    block_size_months: int = 6,\n",
    "    n_years: int = 30,\n",
    "    rng: np.random.Generator = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a block bootstrap sample from historical data.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with date index and return columns\n",
    "        block_size_months: Size of each block in months\n",
    "        n_years: Number of years to generate\n",
    "        rng: numpy random Generator for reproducibility (optional)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with bootstrapped returns\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    \n",
    "    block_size_days = block_size_months * 30  # Approximate calendar days per month\n",
    "    n_days_needed = n_years * 365  # Calendar days per year\n",
    "    \n",
    "    # Adjust block size if data is not long enough\n",
    "    max_block_size = len(data) - 1\n",
    "    if block_size_days > max_block_size:\n",
    "        original_block_size = block_size_days\n",
    "        block_size_days = max(30, max_block_size // 2)  # At least 1 month\n",
    "        print(f\"  Warning: Reducing block size from {original_block_size} to {block_size_days} days due to limited data\")\n",
    "    \n",
    "    n_blocks_needed = int(np.ceil(n_days_needed / block_size_days))\n",
    "    \n",
    "    # Ensure we have enough data\n",
    "    n_possible_blocks = len(data) - block_size_days + 1\n",
    "    \n",
    "    if n_possible_blocks < 1:\n",
    "        raise ValueError(\n",
    "            f\"Not enough data for block size {block_size_days} days. \"\n",
    "            f\"Available data: {len(data)} days. \"\n",
    "            f\"Need at least {block_size_days} days.\"\n",
    "        )\n",
    "    \n",
    "    # Randomly select block start positions using the provided RNG\n",
    "    block_starts = rng.integers(0, n_possible_blocks, size=n_blocks_needed)\n",
    "    \n",
    "    # Concatenate blocks\n",
    "    samples = []\n",
    "    for start in block_starts:\n",
    "        block = data.iloc[start:start + block_size_days].copy()\n",
    "        samples.append(block)\n",
    "    \n",
    "    result = pd.concat(samples, ignore_index=True)\n",
    "    \n",
    "    # Trim to exact length needed\n",
    "    result = result.iloc[:n_days_needed]\n",
    "    \n",
    "    # Reset index to be sequential days\n",
    "    result = result.reset_index(drop=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Load Historical Data\n",
    "\n",
    "Loading all available asset classes and inflation data from CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base path\n",
    "BASE_PATH = Path('..')\n",
    "\n",
    "# Load data\n",
    "print(\"Loading asset data...\")\n",
    "assets = load_asset_data(BASE_PATH)\n",
    "\n",
    "print(\"Loading inflation data...\")\n",
    "inflation_data = load_inflation_data(BASE_PATH)\n",
    "\n",
    "# Show available assets\n",
    "print(\"\\nAvailable assets:\")\n",
    "for name, df in assets.items():\n",
    "    print(f\"  {name}: {len(df)} observations from {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "print(\"\\nAvailable inflation series:\")\n",
    "for name, df in inflation_data.items():\n",
    "    print(f\"  {name}: {len(df)} observations from {df['date'].min()} to {df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Daily Returns\n",
    "\n",
    "Converting price/yield data into daily return series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns for each asset\n",
    "print(\"Calculating returns...\")\n",
    "\n",
    "assets_returns = {}\n",
    "\n",
    "# Equity indices (log returns from prices)\n",
    "for name in ['MSCI_WORLD', 'MSCI_ACWI', 'MSCI_ITALY', 'STOXX_SXXGR']:\n",
    "    assets_returns[name] = calculate_daily_returns(assets[name])\n",
    "\n",
    "# Bond yields (convert to returns using TOTAL RETURN method)\n",
    "# Uses duration approximation: return = yield/365 - duration × Δyield\n",
    "# This captures both income and capital gain/loss from yield changes\n",
    "BOND_DURATION = 8.0  # Modified duration for 10Y bonds\n",
    "\n",
    "for name in ['BTP_10Y', 'OAT_10Y']:\n",
    "    assets_returns[name] = calculate_bond_total_returns(\n",
    "        assets[name], \n",
    "        duration=BOND_DURATION,\n",
    "        yield_in_percent=True\n",
    "    )\n",
    "    print(f\"  {name}: Using total return method with duration={BOND_DURATION}\")\n",
    "\n",
    "# Calculate inflation rates\n",
    "inflation_returns = {}\n",
    "for name, df in inflation_data.items():\n",
    "    inflation_returns[name] = calculate_inflation_rate(df)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VALIDATION: Bond Returns Methodology\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VALIDATION: Bond Returns Methodology\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Sample some extreme days to verify floor is working\n",
    "btp_returns = assets_returns['BTP_10Y']['return']\n",
    "print(f\"\\nBTP 10Y log returns statistics:\")\n",
    "print(f\"  Min daily return: {btp_returns.min():.6f} ({np.exp(btp_returns.min())-1:.4%} simple)\")\n",
    "print(f\"  Max daily return: {btp_returns.max():.6f} ({np.exp(btp_returns.max())-1:.4%} simple)\")\n",
    "print(f\"  Mean daily return: {btp_returns.mean():.6f}\")\n",
    "print(f\"  Std daily return: {btp_returns.std():.6f}\")\n",
    "\n",
    "# Verify compounding works correctly\n",
    "total_log_return = btp_returns.sum()\n",
    "total_simple_return = np.exp(total_log_return) - 1\n",
    "print(f\"\\nTotal period return: {total_simple_return:.2%}\")\n",
    "\n",
    "# Check for any NaN or Inf values\n",
    "print(f\"\\nData quality:\")\n",
    "print(f\"  NaN values: {btp_returns.isna().sum()}\")\n",
    "print(f\"  Inf values: {np.isinf(btp_returns).sum()}\")\n",
    "\n",
    "# Verify that all asset returns are now log returns\n",
    "print(f\"\\n--- Consistency Check: All Returns are Log Returns ---\")\n",
    "for name in assets_returns.keys():\n",
    "    returns = assets_returns[name]['return']\n",
    "    # Log returns are typically small (daily) and can be negative\n",
    "    # Simple returns would have a lower bound of -1 (100% loss)\n",
    "    min_ret = returns.min()\n",
    "    max_ret = returns.max()\n",
    "    print(f\"  {name}: min={min_ret:.6f}, max={max_ret:.6f}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VALIDATION: Inflation Calculation Method\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"INFLATION CALCULATION: Simple Returns vs Log Returns\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate using both methods for comparison\n",
    "hicp_eu = inflation_data['HICP_EU'].copy()\n",
    "\n",
    "# Simple returns (old method)\n",
    "simple_inflation = (hicp_eu['value'] / hicp_eu['value'].shift(1) - 1).dropna()\n",
    "\n",
    "# Log returns (new method - currently used)\n",
    "log_inflation = np.log(hicp_eu['value'] / hicp_eu['value'].shift(1)).dropna()\n",
    "\n",
    "print(f\"\\nPeriod: {hicp_eu['date'].min().strftime('%Y-%m')} to {hicp_eu['date'].max().strftime('%Y-%m')}\")\n",
    "\n",
    "print(f\"\\n--- Monthly Statistics ---\")\n",
    "print(f\"Simple Returns - Mean: {simple_inflation.mean():.6f}, Std: {simple_inflation.std():.6f}\")\n",
    "print(f\"Log Returns    - Mean: {log_inflation.mean():.6f}, Std: {log_inflation.std():.6f}\")\n",
    "\n",
    "print(f\"\\n--- Annualized Statistics ---\")\n",
    "# For simple returns: (1 + mean)^12 - 1\n",
    "annual_simple = (1 + simple_inflation.mean()) ** 12 - 1\n",
    "# For log returns: mean * 12 (then exp - 1 for the rate)\n",
    "annual_log = np.exp(log_inflation.mean() * 12) - 1\n",
    "\n",
    "print(f\"Simple Returns - Annualized: {annual_simple:.4%}\")\n",
    "print(f\"Log Returns    - Annualized: {annual_log:.4%}\")\n",
    "print(f\"Difference: {abs(annual_simple - annual_log):.6%}\")\n",
    "\n",
    "print(f\"\\n--- Compounding Comparison (Full Period) ---\")\n",
    "# Compound simple returns correctly\n",
    "total_simple = np.prod(1 + simple_inflation) - 1\n",
    "# Compound log returns correctly  \n",
    "total_log = np.exp(log_inflation.sum()) - 1\n",
    "\n",
    "print(f\"Total inflation (simple, correct compounding): {total_simple:.2%}\")\n",
    "print(f\"Total inflation (log, correct compounding):    {total_log:.2%}\")\n",
    "print(f\"Difference: {abs(total_simple - total_log):.4%}\")\n",
    "\n",
    "print(f\"\\n✓ Log returns are now used for consistency with equity calculations\")\n",
    "print(f\"  and the simulation's compounding method: exp(sum(log_returns)) - 1\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VALIDATION: Bond Total Return Model\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate returns using both methods\n",
    "btp_income_only = calculate_bond_returns_income_only(assets['BTP_10Y'])\n",
    "btp_total_return = calculate_bond_total_returns(assets['BTP_10Y'], duration=8.0)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BTP 10Y RETURN COMPARISON: Income-Only vs Total Return\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Full period statistics\n",
    "print(\"\\n--- Full Period Statistics ---\")\n",
    "print(f\"Period: {btp_total_return['date'].min().strftime('%Y-%m-%d')} to {btp_total_return['date'].max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Income-only method\n",
    "income_annual_return = btp_income_only['return'].mean() * 365\n",
    "income_annual_vol = btp_income_only['return'].std() * np.sqrt(365)\n",
    "print(f\"\\nIncome-Only Method (OLD - INCORRECT):\")\n",
    "print(f\"  Annualized Return: {income_annual_return:.2%}\")\n",
    "print(f\"  Annualized Volatility: {income_annual_vol:.2%}\")\n",
    "\n",
    "# Total return method\n",
    "total_annual_return = btp_total_return['return'].mean() * 365\n",
    "total_annual_vol = btp_total_return['return'].std() * np.sqrt(365)\n",
    "print(f\"\\nTotal Return Method (NEW - CORRECT):\")\n",
    "print(f\"  Annualized Return: {total_annual_return:.2%}\")\n",
    "print(f\"  Annualized Volatility: {total_annual_vol:.2%}\")\n",
    "\n",
    "print(f\"\\nDifference:\")\n",
    "print(f\"  Return difference: {(total_annual_return - income_annual_return):.2%}\")\n",
    "print(f\"  Volatility ratio: {total_annual_vol / income_annual_vol:.1f}x higher\")\n",
    "\n",
    "# Year-by-year analysis for sanity checks\n",
    "print(\"\\n--- Year-by-Year Returns (Total Return Method) ---\")\n",
    "\n",
    "btp_total_return['year'] = pd.to_datetime(btp_total_return['date']).dt.year\n",
    "yearly_returns = btp_total_return.groupby('year')['return'].apply(\n",
    "    lambda x: np.exp(x.sum()) - 1\n",
    ").reset_index()\n",
    "yearly_returns.columns = ['Year', 'Annual_Return']\n",
    "\n",
    "# Also calculate for income-only\n",
    "btp_income_only['year'] = pd.to_datetime(btp_income_only['date']).dt.year\n",
    "yearly_returns_income = btp_income_only.groupby('year')['return'].apply(\n",
    "    lambda x: np.exp(x.sum()) - 1\n",
    ").reset_index()\n",
    "yearly_returns_income.columns = ['Year', 'Annual_Return_Income']\n",
    "\n",
    "# Merge for comparison\n",
    "yearly_comparison = pd.merge(yearly_returns, yearly_returns_income, on='Year')\n",
    "yearly_comparison['Difference'] = yearly_comparison['Annual_Return'] - yearly_comparison['Annual_Return_Income']\n",
    "\n",
    "print(\"\\nYear    Total_Return  Income_Only   Difference\")\n",
    "print(\"-\" * 50)\n",
    "for _, row in yearly_comparison.iterrows():\n",
    "    print(f\"{int(row['Year'])}    {row['Annual_Return']:>10.2%}    {row['Annual_Return_Income']:>10.2%}    {row['Difference']:>10.2%}\")\n",
    "\n",
    "# Highlight key sanity check years\n",
    "print(\"\\n--- Sanity Checks ---\")\n",
    "if 2022 in yearly_comparison['Year'].values:\n",
    "    ret_2022 = yearly_comparison[yearly_comparison['Year'] == 2022]['Annual_Return'].values[0]\n",
    "    print(f\"2022 (rates rose ~0% to ~2.5%): {ret_2022:.2%}\")\n",
    "    if ret_2022 < -0.10:\n",
    "        print(\"  ✓ PASS: Strong negative return as expected\")\n",
    "    else:\n",
    "        print(\"  ⚠ WARNING: Expected strongly negative return\")\n",
    "\n",
    "# Check 2019 (rates fell significantly)\n",
    "if 2019 in yearly_comparison['Year'].values:\n",
    "    ret_2019 = yearly_comparison[yearly_comparison['Year'] == 2019]['Annual_Return'].values[0]\n",
    "    print(f\"2019 (rates fell): {ret_2019:.2%}\")\n",
    "    if ret_2019 > 0.05:\n",
    "        print(\"  ✓ PASS: Positive return from falling rates\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION: Cumulative Returns Comparison\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# --- Plot 1: Cumulative returns comparison ---\n",
    "ax1 = axes[0, 0]\n",
    "\n",
    "# Calculate cumulative returns (using log returns correctly)\n",
    "# Note: btp_income_only uses simple returns, btp_total_return uses log returns\n",
    "cum_income = np.exp(btp_income_only['return'].cumsum())  # income-only still simple, approximate\n",
    "cum_total = np.exp(btp_total_return['return'].cumsum())   # total return now uses log returns\n",
    "\n",
    "ax1.plot(btp_income_only['date'], cum_income, label='Income-Only (OLD)', alpha=0.8, linewidth=1)\n",
    "ax1.plot(btp_total_return['date'], cum_total, label='Total Return (NEW)', alpha=0.8, linewidth=1)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Cumulative Return (starting = 1)')\n",
    "ax1.set_title('BTP 10Y: Cumulative Returns Comparison', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# --- Plot 2: Rolling 1-year returns comparison ---\n",
    "ax2 = axes[0, 1]\n",
    "\n",
    "# Calculate rolling 1-year returns (365 days)\n",
    "btp_income_only_sorted = btp_income_only.sort_values('date').copy()\n",
    "btp_total_return_sorted = btp_total_return.sort_values('date').copy()\n",
    "\n",
    "rolling_income = btp_income_only_sorted['return'].rolling(window=365).apply(\n",
    "    lambda x: np.exp(x.sum()) - 1\n",
    ")\n",
    "rolling_total = btp_total_return_sorted['return'].rolling(window=365).apply(\n",
    "    lambda x: np.exp(x.sum()) - 1\n",
    ")\n",
    "\n",
    "ax2.plot(btp_income_only_sorted['date'], rolling_income * 100, label='Income-Only', alpha=0.8, linewidth=1)\n",
    "ax2.plot(btp_total_return_sorted['date'], rolling_total * 100, label='Total Return', alpha=0.8, linewidth=1)\n",
    "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Rolling 1-Year Return (%)')\n",
    "ax2.set_title('BTP 10Y: Rolling 1-Year Returns', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 3: Annual returns bar chart ---\n",
    "ax3 = axes[1, 0]\n",
    "\n",
    "years = yearly_comparison['Year'].values\n",
    "x = np.arange(len(years))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax3.bar(x - width/2, yearly_comparison['Annual_Return'] * 100, width, \n",
    "                label='Total Return', color='steelblue')\n",
    "bars2 = ax3.bar(x + width/2, yearly_comparison['Annual_Return_Income'] * 100, width, \n",
    "                label='Income-Only', color='coral')\n",
    "\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Annual Return (%)')\n",
    "ax3.set_title('BTP 10Y: Annual Returns Comparison', fontweight='bold')\n",
    "ax3.set_xticks(x[::2])  # Show every other year\n",
    "ax3.set_xticklabels(years[::2], rotation=45)\n",
    "ax3.legend()\n",
    "ax3.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# --- Plot 4: Return distribution comparison ---\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "ax4.hist(btp_income_only['return'] * 100, bins=100, alpha=0.5, label='Income-Only', density=True)\n",
    "ax4.hist(btp_total_return['return'] * 100, bins=100, alpha=0.5, label='Total Return', density=True)\n",
    "ax4.set_xlabel('Daily Return (%)')\n",
    "ax4.set_ylabel('Density')\n",
    "ax4.set_title('BTP 10Y: Daily Returns Distribution', fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_xlim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observation: The Total Return method captures the much higher volatility\")\n",
    "print(\"of bond investments due to duration effects. The Income-Only method severely\")\n",
    "print(\"underestimates risk and misses capital gains/losses from yield changes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Equity-Bond Correlation Analysis\n",
    "\n",
    "### Why Correlation Matters for a Mixed Portfolio\n",
    "\n",
    "The correlation between equities and bonds is a **critical factor** in determining portfolio risk and the success of a withdrawal strategy. Here's why:\n",
    "\n",
    "1. **Diversification Benefit**: When equity-bond correlation is **negative**, bonds provide a natural hedge against equity market downturns. During market stress, bonds tend to appreciate (as investors flee to safety and yields fall), partially offsetting equity losses.\n",
    "\n",
    "2. **Sequence of Returns Risk**: For retirees withdrawing from their portfolio, the **order** of returns matters enormously. A negative equity-bond correlation during crises helps reduce the severity of drawdowns precisely when they are most damaging.\n",
    "\n",
    "3. **Income-Only vs Total Return**: The income-only method for calculating bond returns **severely underestimates** the true correlation dynamics:\n",
    "   - It captures only the yield component (which is always positive and relatively stable)\n",
    "   - It **misses capital gains** when yields fall during crises (flight to quality)\n",
    "   - It **misses capital losses** when yields rise during inflationary periods\n",
    "   - Result: Income-only correlation is artificially low and doesn't reflect the true diversification benefit\n",
    "\n",
    "### What to Expect\n",
    "\n",
    "The total return method should show:\n",
    "- **More negative correlation during crises** (2001-2002, 2008, 2020): As investors flee to safe assets, bond prices rise while equities fall\n",
    "- **More positive correlation during inflationary periods** (2022): Both asset classes suffer when rates rise unexpectedly\n",
    "- **More variable correlation overall**: The income-only method smooths out the true dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EQUITY-BOND CORRELATION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Define crisis years\n",
    "CRISIS_YEARS = [2001, 2002, 2008, 2020, 2022]\n",
    "\n",
    "# --- Prepare data for correlation analysis ---\n",
    "\n",
    "# Get MSCI World returns\n",
    "msci_returns = assets_returns['MSCI_WORLD'][['date', 'return']].copy()\n",
    "msci_returns.columns = ['date', 'msci_return']\n",
    "\n",
    "# Get BTP returns using both methods\n",
    "btp_income = calculate_bond_returns_income_only(assets['BTP_10Y'])[['date', 'return']].copy()\n",
    "btp_income.columns = ['date', 'btp_income_return']\n",
    "\n",
    "btp_total = calculate_bond_total_returns(assets['BTP_10Y'], duration=8.0)[['date', 'return']].copy()\n",
    "btp_total.columns = ['date', 'btp_total_return']\n",
    "\n",
    "# Merge all data on common dates\n",
    "corr_data = pd.merge(msci_returns, btp_income, on='date', how='inner')\n",
    "corr_data = pd.merge(corr_data, btp_total, on='date', how='inner')\n",
    "corr_data = corr_data.sort_values('date').reset_index(drop=True)\n",
    "corr_data['year'] = pd.to_datetime(corr_data['date']).dt.year\n",
    "\n",
    "# --- Calculate overall correlations ---\n",
    "corr_income_overall = corr_data['msci_return'].corr(corr_data['btp_income_return'])\n",
    "corr_total_overall = corr_data['msci_return'].corr(corr_data['btp_total_return'])\n",
    "\n",
    "# --- Calculate rolling correlations (365 calendar days = 1 year) ---\n",
    "ROLLING_WINDOW = 365\n",
    "\n",
    "# Suppress RuntimeWarnings for correlation calculations (NaN produced when stddev=0)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered')\n",
    "    \n",
    "    corr_data['rolling_corr_income'] = corr_data['msci_return'].rolling(\n",
    "        window=ROLLING_WINDOW\n",
    "    ).corr(corr_data['btp_income_return'])\n",
    "\n",
    "    corr_data['rolling_corr_total'] = corr_data['msci_return'].rolling(\n",
    "        window=ROLLING_WINDOW\n",
    "    ).corr(corr_data['btp_total_return'])\n",
    "\n",
    "    # --- Calculate correlations by year ---\n",
    "    yearly_corr = corr_data.groupby('year').apply(\n",
    "        lambda x: pd.Series({\n",
    "            'corr_income': x['msci_return'].corr(x['btp_income_return']),\n",
    "            'corr_total': x['msci_return'].corr(x['btp_total_return']),\n",
    "            'n_obs': len(x)\n",
    "        }),\n",
    "        include_groups=False\n",
    "    ).reset_index()\n",
    "\n",
    "# --- Calculate correlations by regime ---\n",
    "crisis_mask = corr_data['year'].isin(CRISIS_YEARS)\n",
    "normal_mask = ~crisis_mask\n",
    "\n",
    "corr_crisis_income = corr_data.loc[crisis_mask, 'msci_return'].corr(\n",
    "    corr_data.loc[crisis_mask, 'btp_income_return']\n",
    ")\n",
    "corr_crisis_total = corr_data.loc[crisis_mask, 'msci_return'].corr(\n",
    "    corr_data.loc[crisis_mask, 'btp_total_return']\n",
    ")\n",
    "\n",
    "corr_normal_income = corr_data.loc[normal_mask, 'msci_return'].corr(\n",
    "    corr_data.loc[normal_mask, 'btp_income_return']\n",
    ")\n",
    "corr_normal_total = corr_data.loc[normal_mask, 'msci_return'].corr(\n",
    "    corr_data.loc[normal_mask, 'btp_total_return']\n",
    ")\n",
    "\n",
    "# --- Print summary table ---\n",
    "print(\"=\" * 70)\n",
    "print(\"EQUITY-BOND CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nPeriod: {corr_data['date'].min().strftime('%Y-%m-%d')} - {corr_data['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Observations: {len(corr_data):,} days\")\n",
    "\n",
    "print(\"\\n--- Overall Correlation (full period) ---\")\n",
    "print(f\"Income-Only Method:  {corr_income_overall:>7.4f}\")\n",
    "print(f\"Total Return Method: {corr_total_overall:>7.4f}\")\n",
    "print(f\"Difference:          {corr_total_overall - corr_income_overall:>7.4f}\")\n",
    "\n",
    "print(\"\\n--- Correlation by Crisis Year ---\")\n",
    "print(f\"{'Year':<8} {'Income-Only':>12} {'Total Return':>13}\")\n",
    "print(\"-\" * 35)\n",
    "for year in CRISIS_YEARS:\n",
    "    year_data = yearly_corr[yearly_corr['year'] == year]\n",
    "    if len(year_data) > 0:\n",
    "        income_val = year_data['corr_income'].values[0]\n",
    "        total_val = year_data['corr_total'].values[0]\n",
    "        print(f\"{year:<8} {income_val:>12.4f} {total_val:>13.4f}\")\n",
    "    else:\n",
    "        print(f\"{year:<8} {'N/A':>12} {'N/A':>13}\")\n",
    "\n",
    "print(\"\\n--- Average Correlation by Regime ---\")\n",
    "print(f\"{'Regime':<18} {'Income-Only':>12} {'Total Return':>13}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'Crisis years':<18} {corr_crisis_income:>12.4f} {corr_crisis_total:>13.4f}\")\n",
    "print(f\"{'Normal years':<18} {corr_normal_income:>12.4f} {corr_normal_total:>13.4f}\")\n",
    "\n",
    "print(\"\\n--- Interpretation ---\")\n",
    "if corr_total_overall < corr_income_overall:\n",
    "    print(\">>> The Total Return method shows MORE NEGATIVE correlation overall.\")\n",
    "    print(\"    This captures bond price appreciation when equities fall.\")\n",
    "else:\n",
    "    print(\">>> The Income-Only method shows more negative correlation overall.\")\n",
    "    \n",
    "# Check crisis year behavior\n",
    "crisis_diff = corr_crisis_total - corr_crisis_income\n",
    "normal_diff = corr_normal_total - corr_normal_income\n",
    "if crisis_diff < normal_diff:\n",
    "    print(\">>> The Total Return method better captures the 'flight to quality' effect\")\n",
    "    print(\"    during crises, when bonds act as a hedge for equities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION: Equity-Bond Correlation\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# --- Subplot 1: Rolling Correlation (365 days) ---\n",
    "ax1 = axes[0]\n",
    "\n",
    "# Plot rolling correlations\n",
    "ax1.plot(corr_data['date'], corr_data['rolling_corr_income'], \n",
    "         label='Income-Only', alpha=0.8, linewidth=1.2, color='coral')\n",
    "ax1.plot(corr_data['date'], corr_data['rolling_corr_total'], \n",
    "         label='Total Return', alpha=0.8, linewidth=1.2, color='steelblue')\n",
    "\n",
    "# Add zero line\n",
    "ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5, linewidth=1)\n",
    "\n",
    "# Highlight crisis years with vertical bands\n",
    "crisis_periods = [\n",
    "    ('2001-01-01', '2002-12-31', 'Dot-com'),\n",
    "    ('2008-01-01', '2008-12-31', 'GFC'),\n",
    "    ('2020-01-01', '2020-12-31', 'COVID'),\n",
    "    ('2022-01-01', '2022-12-31', 'Inflation')\n",
    "]\n",
    "\n",
    "for start, end, label in crisis_periods:\n",
    "    start_date = pd.to_datetime(start)\n",
    "    end_date = pd.to_datetime(end)\n",
    "    if start_date >= corr_data['date'].min() and end_date <= corr_data['date'].max():\n",
    "        ax1.axvspan(start_date, end_date, alpha=0.2, color='gray')\n",
    "        # Add label at top of band\n",
    "        mid_date = start_date + (end_date - start_date) / 2\n",
    "        ax1.text(mid_date, ax1.get_ylim()[1] * 0.9 if ax1.get_ylim()[1] > 0 else 0.7, \n",
    "                 label, ha='center', va='top', fontsize=9, alpha=0.7)\n",
    "\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Rolling Correlation (365 days)')\n",
    "ax1.set_title('MSCI World vs BTP 10Y: Rolling 1-Year Correlation', fontweight='bold')\n",
    "ax1.legend(loc='lower left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(-0.8, 0.8)\n",
    "\n",
    "# --- Subplot 2: Bar Chart by Year ---\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Prepare data for bar chart\n",
    "years = yearly_corr['year'].values\n",
    "x = np.arange(len(years))\n",
    "width = 0.35\n",
    "\n",
    "# Color bars differently for crisis years\n",
    "colors_income = ['lightcoral' if y in CRISIS_YEARS else 'coral' for y in years]\n",
    "colors_total = ['lightsteelblue' if y in CRISIS_YEARS else 'steelblue' for y in years]\n",
    "\n",
    "bars1 = ax2.bar(x - width/2, yearly_corr['corr_income'], width, \n",
    "                label='Income-Only', color=colors_income, edgecolor='darkred', linewidth=0.5)\n",
    "bars2 = ax2.bar(x + width/2, yearly_corr['corr_total'], width, \n",
    "                label='Total Return', color=colors_total, edgecolor='darkblue', linewidth=0.5)\n",
    "\n",
    "# Add zero line\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5, linewidth=1)\n",
    "\n",
    "# Mark crisis years\n",
    "for i, year in enumerate(years):\n",
    "    if year in CRISIS_YEARS:\n",
    "        ax2.annotate('*', xy=(i, max(yearly_corr.loc[yearly_corr['year'] == year, 'corr_income'].values[0],\n",
    "                                      yearly_corr.loc[yearly_corr['year'] == year, 'corr_total'].values[0]) + 0.05),\n",
    "                    ha='center', fontsize=14, color='red')\n",
    "\n",
    "ax2.set_xlabel('Year')\n",
    "ax2.set_ylabel('Annual Correlation')\n",
    "ax2.set_title('MSCI World vs BTP 10Y: Annual Correlation by Method\\n(* = Crisis Years)', fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(years, rotation=45, ha='right')\n",
    "ax2.legend(loc='upper left')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "ax2.set_ylim(-0.7, 0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print additional insights\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Find year with most negative correlation\n",
    "most_negative_year = yearly_corr.loc[yearly_corr['corr_total'].idxmin()]\n",
    "print(f\"Most negative correlation (Total Return): {most_negative_year['year']:.0f} ({most_negative_year['corr_total']:.4f})\")\n",
    "\n",
    "# Find year with most positive correlation\n",
    "most_positive_year = yearly_corr.loc[yearly_corr['corr_total'].idxmax()]\n",
    "print(f\"Most positive correlation (Total Return): {most_positive_year['year']:.0f} ({most_positive_year['corr_total']:.4f})\")\n",
    "\n",
    "# Calculate average absolute difference between methods during crises\n",
    "crisis_years_data = yearly_corr[yearly_corr['year'].isin(CRISIS_YEARS)]\n",
    "avg_diff_crisis = (crisis_years_data['corr_total'] - crisis_years_data['corr_income']).mean()\n",
    "print(f\"\\nAverage correlation difference in crisis years: {avg_diff_crisis:+.4f}\")\n",
    "print(\"(Negative = Total Return shows more negative correlation during crises)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Portfolio Configuration\n",
    "\n",
    "### Portfolio Allocation\n",
    "- **70% MSCI World (Net Total Return)**: Global equity exposure across developed markets, dividends reinvested net of withholding taxes\n",
    "- **30% BTP 10Y**: Italian government bonds (Italian government bonds)\n",
    "\n",
    "### Simulation Parameters\n",
    "- **Initial portfolio**: €1,000,000\n",
    "- **Withdrawal rate**: 4% annually (inflation-adjusted)\n",
    "- **Retirement horizon**: 30 years\n",
    "- **Block size**: 6 months (~180 calendar days)\n",
    "- **Simulations**: 100,000 runs\n",
    "- **Inflation**: Euro area HICP\n",
    "\n",
    "### Tax Assumptions\n",
    "- **No capital gains tax**: Withdrawals are assumed to be tax-free\n",
    "- This simplification is appropriate for:\n",
    "  - Tax-advantaged retirement accounts\n",
    "  - Jurisdictions without capital gains tax\n",
    "  - Long-term holdings exempt from taxation\n",
    "  - Theoretical baseline analysis\n",
    "\n",
    "### Customization\n",
    "All parameters can be easily modified in this cell to test different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio allocation (must sum to 1.0)\n",
    "PORTFOLIO_WEIGHTS = {\n",
    "    'MSCI_WORLD': 0.70,  # 70% global stocks (Net Total Return)\n",
    "    'BTP_10Y': 0.30,    # 30% Italian bonds (BTP)\n",
    "}\n",
    "\n",
    "# Inflation to use\n",
    "INFLATION_SERIES = 'HICP_EU'  # EU harmonized inflation\n",
    "\n",
    "# Block bootstrap parameters\n",
    "BLOCK_SIZE_MONTHS = 6  # Size of blocks in months (can be adjusted)\n",
    "\n",
    "# Portfolio parameters\n",
    "INITIAL_PORTFOLIO = 1000000  # Initial portfolio in EUR\n",
    "ANNUAL_WITHDRAWAL_RATE = 0.04  # 4% initial SWR\n",
    "RETIREMENT_YEARS = 30  # Retirement duration in years\n",
    "\n",
    "# Tax assumption: NO capital gains tax applied on withdrawals\n",
    "# This is an idealized scenario - in reality, withdrawals may be subject to taxation\n",
    "# depending on the jurisdiction and account type (taxable vs tax-advantaged)\n",
    "TAX_ON_WITHDRAWALS = False  # No tax applied\n",
    "\n",
    "# Monte Carlo parameters\n",
    "# With parallel processing via joblib, 100k simulations run much faster\n",
    "# Recommended: 100000 for production (reduce for quick testing)\n",
    "N_SIMULATIONS = 100000  # Number of simulations\n",
    "SEED = 42  # For reproducibility\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Validate weights\n",
    "total_weight = sum(PORTFOLIO_WEIGHTS.values())\n",
    "assert abs(total_weight - 1.0) < 0.001, f\"Portfolio weights must sum to 1.0, got {total_weight}\"\n",
    "\n",
    "print(f\"Portfolio allocation:\")\n",
    "for asset, weight in PORTFOLIO_WEIGHTS.items():\n",
    "    print(f\"  {asset}: {weight:.1%}\")\n",
    "print(f\"\\nInflation series: {INFLATION_SERIES}\")\n",
    "print(f\"Block size: {BLOCK_SIZE_MONTHS} months\")\n",
    "print(f\"Number of simulations: {N_SIMULATIONS:,}\")\n",
    "print(f\"Random seed: {SEED}\")\n",
    "print(f\"\\nTax on withdrawals: {'Yes' if TAX_ON_WITHDRAWALS else 'No (tax-free withdrawals)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Prepare Combined Dataset\n",
    "\n",
    "### Data Merging Process\n",
    "1. Find common time window across all assets (latest start date to earliest end date)\n",
    "2. Filter each asset to the common time window\n",
    "3. Merge asset returns on common dates (outer join)\n",
    "4. Calculate weighted portfolio return: 0.7×MSCI_World + 0.3×BTP_10Y\n",
    "5. Upsample monthly inflation to daily frequency\n",
    "6. Backward-fill missing values (using future known values)\n",
    "7. Drop any remaining NaN values at the beginning\n",
    "\n",
    "### Why Backward-Fill?\n",
    "Using backward-fill (bfill) instead of forward-fill ensures that:\n",
    "- Missing values are filled with the next available known value\n",
    "- This avoids look-ahead bias in the opposite direction\n",
    "- More conservative approach for missing data imputation\n",
    "\n",
    "### Output\n",
    "- Combined dataset with daily portfolio returns and inflation\n",
    "- Summary statistics (annualized using 365 days/year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge selected assets\n",
    "selected_assets = {name: assets_returns[name] for name in PORTFOLIO_WEIGHTS.keys()}\n",
    "\n",
    "# Find common time window across all assets\n",
    "# Start date: maximum of all minimum dates (latest start)\n",
    "# End date: minimum of all maximum dates (earliest end)\n",
    "common_start = max(df['date'].min() for df in selected_assets.values())\n",
    "common_end = min(df['date'].max() for df in selected_assets.values())\n",
    "\n",
    "print(f\"Finding common time window:\")\n",
    "for name, df in selected_assets.items():\n",
    "    print(f\"  {name}: {df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"\\nCommon time window: {common_start.strftime('%Y-%m-%d')} to {common_end.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Filter each asset to common time window before merging\n",
    "selected_assets_filtered = {}\n",
    "for name, df in selected_assets.items():\n",
    "    df_filtered = df[(df['date'] >= common_start) & (df['date'] <= common_end)].copy()\n",
    "    selected_assets_filtered[name] = df_filtered\n",
    "    print(f\"  {name} filtered: {len(df_filtered)} observations\")\n",
    "\n",
    "returns_df = merge_to_common_dates(selected_assets_filtered)\n",
    "\n",
    "# Calculate portfolio daily return\n",
    "#returns_df['portfolio_return'] = 0.0\n",
    "#for asset, weight in PORTFOLIO_WEIGHTS.items():\n",
    "#    returns_df['portfolio_return'] += returns_df[asset] * weight\n",
    "\n",
    "# Calculate portfolio daily return\n",
    "# Note: Log returns are NOT cross-sectionally additive, so we must convert\n",
    "# to growth factors, aggregate, then convert back to log return\n",
    "returns_df['portfolio_return'] = calculate_portfolio_log_return(\n",
    "    returns_df, PORTFOLIO_WEIGHTS\n",
    ")\n",
    "\n",
    "# Add inflation\n",
    "inflation_df = inflation_returns[INFLATION_SERIES]\n",
    "inflation_daily = upsample_inflation_to_daily(\n",
    "    inflation_df,\n",
    "    returns_df['date'].min(),\n",
    "    returns_df['date'].max()\n",
    ")\n",
    "\n",
    "# Merge inflation\n",
    "returns_df = pd.merge(returns_df, inflation_daily, on='date', how='left')\n",
    "\n",
    "# Backward fill missing values (bfill) then drop any remaining NaN at the start\n",
    "returns_df = returns_df.bfill().dropna()\n",
    "\n",
    "print(f\"\\nCombined dataset:\")\n",
    "print(f\"  Date range: {returns_df['date'].min()} to {returns_df['date'].max()}\")\n",
    "print(f\"  Total days: {len(returns_df):,}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(returns_df.head())\n",
    "\n",
    "print(f\"\\nSummary statistics (annualized):\")\n",
    "print(f\"  Portfolio return: {returns_df['portfolio_return'].mean() * 365:.2%} ± {returns_df['portfolio_return'].std() * np.sqrt(365):.2%}\")\n",
    "print(f\"  Inflation: {returns_df['inflation'].mean() * 365:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Monte Carlo Simulation Functions\n",
    "\n",
    "### Single Portfolio Simulation\n",
    "`simulate_portfolio_bootstrap()` simulates one retirement scenario:\n",
    "1. **Bootstrap sample**: Generate 30 years of returns using block bootstrap\n",
    "2. **Annual loop**: For each year:\n",
    "   - Compound daily returns to get annual return\n",
    "   - Compound daily inflation to get annual inflation\n",
    "   - Adjust withdrawal for inflation (after year 1)\n",
    "   - Withdraw at beginning of year\n",
    "   - Apply investment returns\n",
    "3. **Portfolio tracking**: Record value each year\n",
    "\n",
    "### Monte Carlo Runner\n",
    "`run_monte_carlo_bootstrap()` runs 100,000 independent simulations:\n",
    "- Each simulation uses different random block samples\n",
    "- Tracks all portfolio paths\n",
    "- Calculates success rate (portfolio > 0 after 30 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_portfolio_bootstrap(\n",
    "    initial_portfolio: float,\n",
    "    withdrawal_rate: float,\n",
    "    years: int,\n",
    "    returns_data: pd.DataFrame,\n",
    "    block_size_months: int = 6,\n",
    "    adjust_for_inflation: bool = True,\n",
    "    rng: np.random.Generator = None\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Simulate portfolio evolution using block bootstrap.\n",
    "    \n",
    "    Note: This simulation assumes NO capital gains tax on withdrawals.\n",
    "    The full withdrawal amount is taken from the portfolio without any\n",
    "    tax deduction. For taxed scenarios, the withdrawal amount should be\n",
    "    grossed up to account for the applicable tax rate.\n",
    "    \n",
    "    Args:\n",
    "        initial_portfolio: Initial portfolio value\n",
    "        withdrawal_rate: Annual withdrawal rate\n",
    "        years: Number of years to simulate\n",
    "        returns_data: Historical returns data\n",
    "        block_size_months: Block size for bootstrap\n",
    "        adjust_for_inflation: Whether to adjust withdrawals for inflation\n",
    "        rng: numpy random Generator for reproducibility (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (portfolio_values, withdrawal_amounts)\n",
    "    \"\"\"\n",
    "    # Generate bootstrap sample\n",
    "    bootstrap_data = block_bootstrap_sample(\n",
    "        returns_data[['portfolio_return', 'inflation']],\n",
    "        block_size_months=block_size_months,\n",
    "        n_years=years,\n",
    "        rng=rng\n",
    "    )\n",
    "    \n",
    "    # Convert daily returns to yearly\n",
    "    days_per_year = len(bootstrap_data) // years\n",
    "    \n",
    "    portfolio = np.zeros(years + 1)\n",
    "    portfolio[0] = initial_portfolio\n",
    "    \n",
    "    withdrawals = np.zeros(years)\n",
    "    annual_withdrawal = initial_portfolio * withdrawal_rate\n",
    "    \n",
    "    for year in range(years):\n",
    "        # Get this year's daily returns\n",
    "        start_idx = year * days_per_year\n",
    "        end_idx = (year + 1) * days_per_year\n",
    "        \n",
    "        year_data = bootstrap_data.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Annual return (compound daily returns)\n",
    "        annual_return = np.exp(year_data['portfolio_return'].sum()) - 1\n",
    "        \n",
    "        # Annual inflation (compound daily inflation)\n",
    "        annual_inflation = np.exp(year_data['inflation'].sum()) - 1\n",
    "        \n",
    "        # Adjust withdrawal for inflation if requested\n",
    "        if adjust_for_inflation and year > 0:\n",
    "            annual_withdrawal *= (1 + annual_inflation)\n",
    "        \n",
    "        withdrawals[year] = annual_withdrawal\n",
    "        \n",
    "        # Withdrawal at the beginning of the year\n",
    "        # NOTE: No capital gains tax is applied - the full withdrawal amount\n",
    "        # is taken from the portfolio. In a taxed scenario, to receive the same\n",
    "        # net amount, a higher gross withdrawal would be needed.\n",
    "        portfolio[year + 1] = portfolio[year] - annual_withdrawal\n",
    "        \n",
    "        # Apply returns\n",
    "        if portfolio[year + 1] > 0:\n",
    "            portfolio[year + 1] *= (1 + annual_return)\n",
    "        else:\n",
    "            portfolio[year + 1] = 0  # Portfolio depleted\n",
    "    \n",
    "    return portfolio, withdrawals\n",
    "\n",
    "\n",
    "def _run_single_simulation(\n",
    "    sim_id: int,\n",
    "    seed: int,\n",
    "    initial_portfolio: float,\n",
    "    withdrawal_rate: float,\n",
    "    years: int,\n",
    "    returns_data: pd.DataFrame,\n",
    "    block_size_months: int,\n",
    "    adjust_for_inflation: bool\n",
    ") -> Tuple[int, np.ndarray, bool]:\n",
    "    \"\"\"\n",
    "    Wrapper function to run a single simulation with deterministic seed.\n",
    "    \n",
    "    Args:\n",
    "        sim_id: Simulation identifier\n",
    "        seed: Deterministic seed for this simulation's RNG\n",
    "        initial_portfolio: Initial portfolio value\n",
    "        withdrawal_rate: Annual withdrawal rate\n",
    "        years: Number of years to simulate\n",
    "        returns_data: Historical returns data\n",
    "        block_size_months: Block size for bootstrap\n",
    "        adjust_for_inflation: Whether to adjust withdrawals for inflation\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (simulation_id, portfolio_values, success)\n",
    "    \"\"\"\n",
    "    # Create deterministic generator for this simulation\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    portfolio, _ = simulate_portfolio_bootstrap(\n",
    "        initial_portfolio,\n",
    "        withdrawal_rate,\n",
    "        years,\n",
    "        returns_data,\n",
    "        block_size_months,\n",
    "        adjust_for_inflation,\n",
    "        rng=rng\n",
    "    )\n",
    "    success = portfolio[-1] > 0\n",
    "    return sim_id, portfolio, success\n",
    "\n",
    "\n",
    "def run_monte_carlo_bootstrap(\n",
    "    n_simulations: int,\n",
    "    initial_portfolio: float,\n",
    "    withdrawal_rate: float,\n",
    "    years: int,\n",
    "    returns_data: pd.DataFrame,\n",
    "    block_size_months: int = 6,\n",
    "    adjust_for_inflation: bool = True,\n",
    "    n_jobs: int = -1,\n",
    "    base_seed: int = 42\n",
    ") -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Run Monte Carlo simulations using block bootstrap with parallel processing.\n",
    "    \n",
    "    Note: All simulations assume NO capital gains tax on withdrawals.\n",
    "    \n",
    "    REPRODUCIBILITY: Each simulation receives a deterministic seed = base_seed + sim_id\n",
    "    \n",
    "    Args:\n",
    "        n_simulations: Number of simulations to run\n",
    "        initial_portfolio: Initial portfolio value\n",
    "        withdrawal_rate: Annual withdrawal rate\n",
    "        years: Number of years to simulate\n",
    "        returns_data: Historical returns data\n",
    "        block_size_months: Block size for bootstrap\n",
    "        adjust_for_inflation: Whether to adjust withdrawals for inflation\n",
    "        n_jobs: Number of parallel jobs (-1 uses all available CPUs)\n",
    "        base_seed: Base seed for reproducibility (each simulation uses base_seed + sim_id)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (all_portfolios, success_rate)\n",
    "    \"\"\"\n",
    "    print(f\"  Running {n_simulations:,} simulations using {n_jobs if n_jobs > 0 else 'all available'} CPU(s)...\")\n",
    "    print(f\"  Base seed: {base_seed} (reproducible)\")\n",
    "    \n",
    "    # Run simulations in parallel with deterministic seeds\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=10)(\n",
    "        delayed(_run_single_simulation)(\n",
    "            i,\n",
    "            base_seed + i,  # Deterministic seed for each simulation\n",
    "            initial_portfolio,\n",
    "            withdrawal_rate,\n",
    "            years,\n",
    "            returns_data,\n",
    "            block_size_months,\n",
    "            adjust_for_inflation\n",
    "        )\n",
    "        for i in range(n_simulations)\n",
    "    )\n",
    "    \n",
    "    # Collect results\n",
    "    all_portfolios = np.zeros((n_simulations, years + 1))\n",
    "    successes = 0\n",
    "    \n",
    "    for sim_id, portfolio, success in results:\n",
    "        all_portfolios[sim_id] = portfolio\n",
    "        if success:\n",
    "            successes += 1\n",
    "    \n",
    "    success_rate = successes / n_simulations\n",
    "    return all_portfolios, success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Run Base Simulation\n",
    "\n",
    "Executing 100,000 Monte Carlo simulations with 4% withdrawal rate.\n",
    "\n",
    "**Expected runtime**: 2-5 minutes depending on system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running {N_SIMULATIONS:,} Monte Carlo simulations...\")\n",
    "portfolios, success_rate = run_monte_carlo_bootstrap(\n",
    "    N_SIMULATIONS,\n",
    "    INITIAL_PORTFOLIO,\n",
    "    ANNUAL_WITHDRAWAL_RATE,\n",
    "    RETIREMENT_YEARS,\n",
    "    returns_df,\n",
    "    BLOCK_SIZE_MONTHS,\n",
    "    base_seed=SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Success rate: {success_rate:.2%}\")\n",
    "print(f\"  Median final value: €{np.median(portfolios[:, -1]):,.0f}\")\n",
    "print(f\"  Mean final value: €{np.mean(portfolios[:, -1]):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TEST REPRODUCIBILITY ===\n",
    "# Run this cell to verify that simulations are deterministic\n",
    "\n",
    "def test_reproducibility(n_test=1000):\n",
    "    \"\"\"Verify that simulations are reproducible.\"\"\"\n",
    "    print(\"Testing reproducibility...\")\n",
    "    \n",
    "    p1, sr1 = run_monte_carlo_bootstrap(\n",
    "        n_test, INITIAL_PORTFOLIO, ANNUAL_WITHDRAWAL_RATE,\n",
    "        RETIREMENT_YEARS, returns_df, BLOCK_SIZE_MONTHS,\n",
    "        n_jobs=-1, base_seed=42\n",
    "    )\n",
    "    \n",
    "    p2, sr2 = run_monte_carlo_bootstrap(\n",
    "        n_test, INITIAL_PORTFOLIO, ANNUAL_WITHDRAWAL_RATE,\n",
    "        RETIREMENT_YEARS, returns_df, BLOCK_SIZE_MONTHS,\n",
    "        n_jobs=-1, base_seed=42\n",
    "    )\n",
    "    \n",
    "    assert sr1 == sr2, f\"Success rates differ: {sr1} vs {sr2}\"\n",
    "    assert np.allclose(p1, p2), \"Portfolio paths differ!\"\n",
    "    print(\"✓ Reproducibility verified!\")\n",
    "\n",
    "# Uncomment to run the test:\n",
    "# test_reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Results Visualization\n",
    "\n",
    "### Portfolio Evolution Chart\n",
    "Shows percentile bands across 30-year horizon:\n",
    "- **5th percentile**: Lower bound scenarios\n",
    "- **25th percentile**: Below-average outcomes\n",
    "- **50th percentile** (median): Central tendency\n",
    "- **75th percentile**: Above-average outcomes\n",
    "- **95th percentile**: Upper bound scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio evolution plot\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "years = np.arange(0, RETIREMENT_YEARS + 1)\n",
    "\n",
    "# Percentiles\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "colors = ['#d62728', '#ff7f0e', '#2ca02c', '#ff7f0e', '#d62728']\n",
    "\n",
    "for i, p in enumerate(percentiles):\n",
    "    values = np.percentile(portfolios, p, axis=0)\n",
    "    ax.plot(years, values, label=f'{p}th percentile', \n",
    "            color=colors[i], linewidth=2 if p == 50 else 1.5)\n",
    "\n",
    "# Zero line\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Retirement years', fontsize=12)\n",
    "ax.set_ylabel('Portfolio value (EUR)', fontsize=12)\n",
    "ax.set_title(\n",
    "    f'Monte Carlo Simulation with Block Bootstrap - {N_SIMULATIONS:,} simulations\\n'\n",
    "    f'SWR: {ANNUAL_WITHDRAWAL_RATE:.1%}, Block size: {BLOCK_SIZE_MONTHS} months, Success rate: {success_rate:.1%}',\n",
    "    fontsize=14, fontweight='bold'\n",
    ")\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'€{x/1000:.0f}k'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Portfolio Values Distribution\n",
    "\n",
    "Histogram showing distribution of portfolio values after 30 years:\n",
    "- Values **below zero** (left of red line): Failed scenarios\n",
    "- Values **above zero**: Successful scenarios\n",
    "- **Green line**: Median final value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final values distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "final_values = portfolios[:, -1]\n",
    "ax.hist(final_values, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Depletion')\n",
    "ax.axvline(x=np.median(final_values), color='green', linestyle='--',\n",
    "           linewidth=2, label=f'Median: €{np.median(final_values):,.0f}')\n",
    "\n",
    "ax.set_xlabel('Final portfolio value (EUR)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title(\n",
    "    f'Final values distribution after {RETIREMENT_YEARS} years',\n",
    "    fontsize=14, fontweight='bold'\n",
    ")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'€{x/1000:.0f}k'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final values distribution - ZOOMED (0 to median * 3)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "median_value = np.median(final_values)\n",
    "max_x = median_value * 3\n",
    "\n",
    "# Filter values for the zoomed view (only for counting, we still plot all data)\n",
    "ax.hist(final_values, bins=50, edgecolor='black', alpha=0.7, range=(final_values.min(), max_x))\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Depletion')\n",
    "ax.axvline(x=median_value, color='green', linestyle='--',\n",
    "           linewidth=2, label=f'Median: €{median_value:,.0f}')\n",
    "\n",
    "ax.set_xlabel('Final portfolio value (EUR)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title(\n",
    "    f'Final values distribution after {RETIREMENT_YEARS} years (zoomed: 0 to median×3)',\n",
    "    fontsize=14, fontweight='bold'\n",
    ")\n",
    "ax.set_xlim(0, max_x)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'€{x/1000:.0f}k'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Sensitivity Analysis\n",
    "\n",
    "### Withdrawal Rate Impact\n",
    "Testing withdrawal rates from 2% to 5% (in 0.1% increments) to understand:\n",
    "- How success rate changes with withdrawal rate\n",
    "- What is the maximum sustainable withdrawal rate?\n",
    "- Trade-off between spending and portfolio longevity\n",
    "\n",
    "**Expected runtime**: 15-30 minutes (10 different rates × 100,000 simulations each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different withdrawal rates\n",
    "withdrawal_rates = np.arange(0.02, 0.051, 0.001)\n",
    "success_rates = []\n",
    "\n",
    "print(\"Testing different withdrawal rates...\")\n",
    "for wr in withdrawal_rates:\n",
    "    print(f\"\\nWithdrawal rate: {wr:.1%}\")\n",
    "    _, sr = run_monte_carlo_bootstrap(\n",
    "        N_SIMULATIONS,\n",
    "        INITIAL_PORTFOLIO,\n",
    "        wr,\n",
    "        RETIREMENT_YEARS,\n",
    "        returns_df,\n",
    "        BLOCK_SIZE_MONTHS\n",
    "    )\n",
    "    success_rates.append(sr)\n",
    "    print(f\"  Success rate: {sr:.2%}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "df_wr = pd.DataFrame({\n",
    "    'Withdrawal_Rate': withdrawal_rates,\n",
    "    'Success_Rate': success_rates\n",
    "})\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(df_wr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity Curve\n",
    "\n",
    "This chart shows the relationship between withdrawal rate and success probability:\n",
    "- **99% threshold** (green): Conservative safety level\n",
    "- **95% threshold** (orange): Moderate safety level\n",
    "- **90% threshold** (red): Acceptable risk level\n",
    "- Find the withdrawal rate that meets your risk tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Withdrawal rate sensitivity plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(withdrawal_rates * 100, np.array(success_rates) * 100, \n",
    "        marker='o', linewidth=2, markersize=6)\n",
    "ax.axhline(y=99, color='green', linestyle='--', label='99% safety threshold')\n",
    "ax.axhline(y=95, color='orange', linestyle='--', label='95% safety threshold')\n",
    "ax.axhline(y=90, color='red', linestyle='--', label='90% safety threshold')\n",
    "\n",
    "ax.set_xlabel('Annual withdrawal rate (%)', fontsize=12)\n",
    "ax.set_ylabel('Success rate (%)', fontsize=12)\n",
    "ax.set_title(\n",
    "    f'Sensitivity Analysis - Withdrawal Rate vs Success Rate\\n'\n",
    "    f'({RETIREMENT_YEARS} years, {N_SIMULATIONS:,} simulations, {BLOCK_SIZE_MONTHS}-month blocks)',\n",
    "    fontsize=14, fontweight='bold'\n",
    ")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 105])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Detailed Statistical Analysis\n",
    "\n",
    "### Year-by-Year Statistics\n",
    "For each year of retirement, showing:\n",
    "- **Median/Mean**: Central tendency\n",
    "- **P5/P25/P75/P95**: Distribution spread\n",
    "- **Failure_Prob**: Cumulative probability of depletion by that year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for each year\n",
    "stats_df = pd.DataFrame({\n",
    "    'Year': range(RETIREMENT_YEARS + 1),\n",
    "    'Median': np.median(portfolios, axis=0),\n",
    "    'Mean': np.mean(portfolios, axis=0),\n",
    "    'P5': np.percentile(portfolios, 5, axis=0),\n",
    "    'P25': np.percentile(portfolios, 25, axis=0),\n",
    "    'P75': np.percentile(portfolios, 75, axis=0),\n",
    "    'P95': np.percentile(portfolios, 95, axis=0),\n",
    "    'Failure_Prob': np.sum(portfolios <= 0, axis=0) / N_SIMULATIONS\n",
    "})\n",
    "\n",
    "print(\"Portfolio evolution statistics (all years):\")\n",
    "print(stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Enhanced Depletion Analysis\n",
    "\n",
    "This section provides a comprehensive analysis of portfolio depletion scenarios, including:\n",
    "- **Depletion year distribution**: When do portfolios fail?\n",
    "- **Time-band analysis**: Early vs mid vs late failures\n",
    "- **Hazard rates**: Conditional probability of failure given survival\n",
    "- **Pre-depletion values**: Portfolio state before failure\n",
    "- **Survival curves**: Probability of portfolio survival over time\n",
    "- **Sample trajectories**: Visual representation of individual paths\n",
    "\n",
    "Understanding depletion patterns helps identify:\n",
    "1. **Sequence of returns risk**: Early failures often indicate poor market conditions at the start\n",
    "2. **Near-miss scenarios**: Late failures suggest the withdrawal rate was barely unsustainable\n",
    "3. **Risk periods**: When is the portfolio most vulnerable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEPLETION YEAR ANALYSIS: Basic Distribution\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate depletion years for all failed simulations\n",
    "depletion_years = []\n",
    "for portfolio in portfolios:\n",
    "    if portfolio[-1] <= 0:\n",
    "        depletion_year = np.where(portfolio <= 0)[0]\n",
    "        if len(depletion_year) > 0:\n",
    "            depletion_years.append(depletion_year[0])\n",
    "\n",
    "if depletion_years:\n",
    "    # Basic histogram of depletion years\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.hist(depletion_years, bins=RETIREMENT_YEARS, edgecolor='black', alpha=0.7, color='indianred')\n",
    "    ax.axvline(x=np.median(depletion_years), color='darkred', linestyle='--', linewidth=2, \n",
    "               label=f'Median: Year {np.median(depletion_years):.0f}')\n",
    "    ax.axvline(x=np.mean(depletion_years), color='orange', linestyle='--', linewidth=2, \n",
    "               label=f'Mean: Year {np.mean(depletion_years):.1f}')\n",
    "    ax.set_xlabel('Depletion Year', fontsize=12)\n",
    "    ax.set_ylabel('Number of Simulations', fontsize=12)\n",
    "    ax.set_title(\n",
    "        f'Portfolio Depletion Year Distribution\\n'\n",
    "        f'({len(depletion_years):,} failed simulations out of {N_SIMULATIONS:,} = {len(depletion_years)/N_SIMULATIONS:.2%} failure rate)',\n",
    "        fontsize=14, fontweight='bold'\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nBasic Depletion Statistics:\")\n",
    "    print(f\"  Total failures: {len(depletion_years):,} ({len(depletion_years)/N_SIMULATIONS:.2%})\")\n",
    "    print(f\"  Median depletion year: {np.median(depletion_years):.0f}\")\n",
    "    print(f\"  Mean depletion year: {np.mean(depletion_years):.1f}\")\n",
    "else:\n",
    "    print(\"\\n✓ No simulation resulted in portfolio depletion!\")\n",
    "    print(\"  All portfolios survived the full retirement period.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEPLETION YEAR ANALYSIS: Percentiles and Time-Band Distribution\n",
    "# ============================================================================\n",
    "\n",
    "if depletion_years:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"DEPLETION YEAR PERCENTILES AND TIME-BAND ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Percentile analysis\n",
    "    print(\"\\n--- Depletion Year Percentiles ---\")\n",
    "    percentiles_to_calc = [5, 10, 25, 50, 75, 90, 95]\n",
    "    for p in percentiles_to_calc:\n",
    "        print(f\"  P{p}: Year {np.percentile(depletion_years, p):.1f}\")\n",
    "    \n",
    "    print(f\"\\n  Standard deviation: {np.std(depletion_years):.2f} years\")\n",
    "    print(f\"  Min depletion year: {np.min(depletion_years)}\")\n",
    "    print(f\"  Max depletion year: {np.max(depletion_years)}\")\n",
    "    \n",
    "    # Time-band analysis: Early (1-10), Mid (11-20), Late (21-30)\n",
    "    print(\"\\n--- Time-Band Distribution ---\")\n",
    "    early_failures = sum(1 for y in depletion_years if y <= 10)\n",
    "    mid_failures = sum(1 for y in depletion_years if 10 < y <= 20)\n",
    "    late_failures = sum(1 for y in depletion_years if y > 20)\n",
    "    \n",
    "    print(f\"  Early failures (years 1-10):  {early_failures:>6,} ({early_failures/len(depletion_years)*100:>5.1f}%)\")\n",
    "    print(f\"  Mid failures (years 11-20):   {mid_failures:>6,} ({mid_failures/len(depletion_years)*100:>5.1f}%)\")\n",
    "    print(f\"  Late failures (years 21-30):  {late_failures:>6,} ({late_failures/len(depletion_years)*100:>5.1f}%)\")\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\n--- Interpretation ---\")\n",
    "    if early_failures > late_failures:\n",
    "        print(\"  ⚠ More early failures suggest high sensitivity to sequence of returns risk.\")\n",
    "        print(\"    Poor market conditions in early retirement are most damaging.\")\n",
    "    elif late_failures > early_failures:\n",
    "        print(\"  ✓ More late failures suggest the withdrawal rate is marginally sustainable.\")\n",
    "        print(\"    Most portfolios nearly made it through the full period.\")\n",
    "    else:\n",
    "        print(\"  Failures are relatively evenly distributed across the retirement period.\")\n",
    "    \n",
    "    # Visualize time-band distribution\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bands = ['Years 1-10\\n(Early)', 'Years 11-20\\n(Mid)', 'Years 21-30\\n(Late)']\n",
    "    counts = [early_failures, mid_failures, late_failures]\n",
    "    colors = ['#d62728', '#ff7f0e', '#2ca02c']  # Red, Orange, Green\n",
    "    \n",
    "    bars = ax.bar(bands, counts, color=colors, edgecolor='black', alpha=0.8)\n",
    "    \n",
    "    # Add percentage labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{count:,}\\n({count/len(depletion_years)*100:.1f}%)',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel('Number of Failures', fontsize=12)\n",
    "    ax.set_title(f'Depletion Distribution by Time Band\\n(Total failures: {len(depletion_years):,})', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"No depletion events to analyze - all portfolios survived!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HAZARD RATE ANALYSIS: Conditional Probability of Failure\n",
    "# ============================================================================\n",
    "# The hazard rate h(t) represents the probability of failing at time t,\n",
    "# given that the portfolio survived until time t-1.\n",
    "# Formula: h(t) = P(fail at t | survived to t-1) = failures_at_t / survived_to_t-1\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HAZARD RATE ANALYSIS: Conditional Probability of Failure\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nHazard rate = P(depletion in year t | survived to year t-1)\")\n",
    "print(\"This measures the 'instantaneous' risk of failure at each point in time.\\n\")\n",
    "\n",
    "# Calculate hazard rates for each year\n",
    "hazard_rates = []\n",
    "years_survived = []\n",
    "years_failed = []\n",
    "\n",
    "for year in range(1, RETIREMENT_YEARS + 1):\n",
    "    # Number of portfolios that survived to year-1 (still positive at end of year-1)\n",
    "    survived_to_prev_year = np.sum(portfolios[:, year-1] > 0)\n",
    "    \n",
    "    # Number that failed exactly in year t (positive at t-1, zero/negative at t)\n",
    "    failed_in_year = np.sum((portfolios[:, year-1] > 0) & (portfolios[:, year] <= 0))\n",
    "    \n",
    "    # Hazard rate\n",
    "    hazard = failed_in_year / survived_to_prev_year if survived_to_prev_year > 0 else 0\n",
    "    \n",
    "    hazard_rates.append(hazard)\n",
    "    years_survived.append(survived_to_prev_year)\n",
    "    years_failed.append(failed_in_year)\n",
    "\n",
    "# Create DataFrame for display\n",
    "hazard_df = pd.DataFrame({\n",
    "    'Year': range(1, RETIREMENT_YEARS + 1),\n",
    "    'Survived_Start': years_survived,\n",
    "    'Failed_This_Year': years_failed,\n",
    "    'Hazard_Rate': hazard_rates\n",
    "})\n",
    "\n",
    "# Print summary for key years\n",
    "print(\"--- Hazard Rates at Key Years ---\")\n",
    "key_years = [1, 5, 10, 15, 20, 25, 30]\n",
    "for year in key_years:\n",
    "    row = hazard_df[hazard_df['Year'] == year].iloc[0]\n",
    "    print(f\"  Year {year:>2}: {row['Hazard_Rate']*100:>6.3f}% \"\n",
    "          f\"({row['Failed_This_Year']:>5,} failures / {row['Survived_Start']:>6,} at risk)\")\n",
    "\n",
    "# Find peak hazard year\n",
    "peak_hazard_idx = np.argmax(hazard_rates)\n",
    "peak_hazard_year = peak_hazard_idx + 1\n",
    "print(f\"\\n  Peak hazard year: {peak_hazard_year} ({hazard_rates[peak_hazard_idx]*100:.3f}%)\")\n",
    "\n",
    "# Average hazard rate by period\n",
    "avg_hazard_early = np.mean(hazard_rates[:10])\n",
    "avg_hazard_mid = np.mean(hazard_rates[10:20])\n",
    "avg_hazard_late = np.mean(hazard_rates[20:])\n",
    "\n",
    "print(f\"\\n--- Average Hazard Rate by Period ---\")\n",
    "print(f\"  Years 1-10:  {avg_hazard_early*100:.3f}%\")\n",
    "print(f\"  Years 11-20: {avg_hazard_mid*100:.3f}%\")\n",
    "print(f\"  Years 21-30: {avg_hazard_late*100:.3f}%\")\n",
    "\n",
    "# Plot hazard rate over time\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.bar(range(1, RETIREMENT_YEARS + 1), np.array(hazard_rates) * 100, \n",
    "       color='steelblue', edgecolor='black', alpha=0.8)\n",
    "ax.axhline(y=np.mean(hazard_rates) * 100, color='red', linestyle='--', linewidth=2,\n",
    "           label=f'Average: {np.mean(hazard_rates)*100:.3f}%')\n",
    "\n",
    "ax.set_xlabel('Year', fontsize=12)\n",
    "ax.set_ylabel('Hazard Rate (%)', fontsize=12)\n",
    "ax.set_title('Annual Hazard Rate: Conditional Probability of Depletion\\n'\n",
    "             'h(t) = P(fail in year t | survived to year t-1)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_xticks(range(0, RETIREMENT_YEARS + 1, 5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PRE-DEPLETION PORTFOLIO VALUE ANALYSIS\n",
    "# ============================================================================\n",
    "# Analyze the portfolio value one year before depletion occurred.\n",
    "# This helps understand how quickly portfolios deteriorate before failing.\n",
    "\n",
    "if depletion_years:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"PRE-DEPLETION PORTFOLIO VALUE ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nThis analysis examines portfolio values one year before depletion,\")\n",
    "    print(\"helping to identify warning signs and the speed of deterioration.\\n\")\n",
    "    \n",
    "    # Calculate portfolio value 1 year before depletion\n",
    "    pre_depletion_values = []\n",
    "    depletion_info = []\n",
    "    \n",
    "    for i, portfolio in enumerate(portfolios):\n",
    "        if portfolio[-1] <= 0:\n",
    "            dep_year = np.where(portfolio <= 0)[0]\n",
    "            if len(dep_year) > 0:\n",
    "                dep_yr = dep_year[0]\n",
    "                if dep_yr > 0:\n",
    "                    pre_val = portfolio[dep_yr - 1]\n",
    "                    pre_depletion_values.append(pre_val)\n",
    "                    depletion_info.append({\n",
    "                        'sim_id': i,\n",
    "                        'depletion_year': dep_yr,\n",
    "                        'pre_depletion_value': pre_val,\n",
    "                        'as_pct_initial': pre_val / INITIAL_PORTFOLIO * 100\n",
    "                    })\n",
    "    \n",
    "    pre_depletion_df = pd.DataFrame(depletion_info)\n",
    "    \n",
    "    print(\"--- Pre-Depletion Portfolio Values (1 year before failure) ---\")\n",
    "    print(f\"  Mean:   €{np.mean(pre_depletion_values):>12,.0f} ({np.mean(pre_depletion_values)/INITIAL_PORTFOLIO*100:.1f}% of initial)\")\n",
    "    print(f\"  Median: €{np.median(pre_depletion_values):>12,.0f} ({np.median(pre_depletion_values)/INITIAL_PORTFOLIO*100:.1f}% of initial)\")\n",
    "    print(f\"  Std:    €{np.std(pre_depletion_values):>12,.0f}\")\n",
    "    print(f\"  Min:    €{np.min(pre_depletion_values):>12,.0f}\")\n",
    "    print(f\"  Max:    €{np.max(pre_depletion_values):>12,.0f}\")\n",
    "    \n",
    "    # Annual withdrawal for context\n",
    "    first_year_withdrawal = INITIAL_PORTFOLIO * ANNUAL_WITHDRAWAL_RATE\n",
    "    print(f\"\\n  (For reference: initial annual withdrawal = €{first_year_withdrawal:,.0f})\")\n",
    "    print(f\"  Median pre-depletion value = {np.median(pre_depletion_values)/first_year_withdrawal:.1f}x annual withdrawal\")\n",
    "    \n",
    "    # Distribution by depletion year\n",
    "    print(\"\\n--- Average Pre-Depletion Value by Time Band ---\")\n",
    "    early_pre = [row['pre_depletion_value'] for row in depletion_info if row['depletion_year'] <= 10]\n",
    "    mid_pre = [row['pre_depletion_value'] for row in depletion_info if 10 < row['depletion_year'] <= 20]\n",
    "    late_pre = [row['pre_depletion_value'] for row in depletion_info if row['depletion_year'] > 20]\n",
    "    \n",
    "    if early_pre:\n",
    "        print(f\"  Early failures (yrs 1-10):  €{np.mean(early_pre):>12,.0f} (n={len(early_pre)})\")\n",
    "    if mid_pre:\n",
    "        print(f\"  Mid failures (yrs 11-20):   €{np.mean(mid_pre):>12,.0f} (n={len(mid_pre)})\")\n",
    "    if late_pre:\n",
    "        print(f\"  Late failures (yrs 21-30):  €{np.mean(late_pre):>12,.0f} (n={len(late_pre)})\")\n",
    "    \n",
    "    # Visualization: histogram of pre-depletion values\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Left: Histogram of pre-depletion values\n",
    "    ax1 = axes[0]\n",
    "    ax1.hist(pre_depletion_values, bins=40, edgecolor='black', alpha=0.7, color='coral')\n",
    "    ax1.axvline(x=np.median(pre_depletion_values), color='darkred', linestyle='--', linewidth=2,\n",
    "                label=f'Median: €{np.median(pre_depletion_values):,.0f}')\n",
    "    ax1.axvline(x=first_year_withdrawal, color='green', linestyle=':', linewidth=2,\n",
    "                label=f'Annual withdrawal: €{first_year_withdrawal:,.0f}')\n",
    "    ax1.set_xlabel('Portfolio Value (EUR)', fontsize=11)\n",
    "    ax1.set_ylabel('Number of Simulations', fontsize=11)\n",
    "    ax1.set_title('Portfolio Value 1 Year Before Depletion', fontsize=12, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'€{x/1000:.0f}k'))\n",
    "    \n",
    "    # Right: Scatter plot of depletion year vs pre-depletion value\n",
    "    ax2 = axes[1]\n",
    "    ax2.scatter(pre_depletion_df['depletion_year'], pre_depletion_df['pre_depletion_value'],\n",
    "                alpha=0.3, s=10, c='steelblue')\n",
    "    \n",
    "    # Add trend line (average per year)\n",
    "    yearly_avg = pre_depletion_df.groupby('depletion_year')['pre_depletion_value'].mean()\n",
    "    ax2.plot(yearly_avg.index, yearly_avg.values, 'r-', linewidth=2, label='Average per year')\n",
    "    \n",
    "    ax2.set_xlabel('Depletion Year', fontsize=11)\n",
    "    ax2.set_ylabel('Portfolio Value 1 Year Before (EUR)', fontsize=11)\n",
    "    ax2.set_title('Pre-Depletion Value vs Depletion Year', fontsize=12, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'€{x/1000:.0f}k'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"No depletion events to analyze - all portfolios survived!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SURVIVAL CURVE (Kaplan-Meier Style)\n",
    "# ============================================================================\n",
    "# The survival curve S(t) shows the probability that a portfolio is still\n",
    "# \"alive\" (value > 0) at each point in time.\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SURVIVAL CURVE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThe survival curve shows the percentage of portfolios still solvent\")\n",
    "print(\"at each point during the retirement period.\\n\")\n",
    "\n",
    "# Calculate survival rate at each year\n",
    "survival_rates = []\n",
    "for year in range(RETIREMENT_YEARS + 1):\n",
    "    n_survived = np.sum(portfolios[:, year] > 0)\n",
    "    survival_rates.append(n_survived / N_SIMULATIONS)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left: Survival Curve\n",
    "ax1 = axes[0]\n",
    "years_plot = np.arange(0, RETIREMENT_YEARS + 1)\n",
    "\n",
    "ax1.plot(years_plot, np.array(survival_rates) * 100, 'b-', linewidth=2.5, label='Survival Rate')\n",
    "ax1.fill_between(years_plot, np.array(survival_rates) * 100, alpha=0.2, color='blue')\n",
    "\n",
    "# Add reference lines\n",
    "ax1.axhline(y=95, color='green', linestyle='--', linewidth=1.5, alpha=0.7, label='95% threshold')\n",
    "ax1.axhline(y=90, color='orange', linestyle='--', linewidth=1.5, alpha=0.7, label='90% threshold')\n",
    "\n",
    "# Mark final survival rate\n",
    "final_survival = survival_rates[-1] * 100\n",
    "ax1.scatter([RETIREMENT_YEARS], [final_survival], color='red', s=100, zorder=5)\n",
    "ax1.annotate(f'{final_survival:.1f}%', \n",
    "             xy=(RETIREMENT_YEARS, final_survival),\n",
    "             xytext=(RETIREMENT_YEARS - 3, final_survival - 5),\n",
    "             fontsize=11, fontweight='bold',\n",
    "             arrowprops=dict(arrowstyle='->', color='red'))\n",
    "\n",
    "ax1.set_xlabel('Year', fontsize=12)\n",
    "ax1.set_ylabel('Survival Rate (%)', fontsize=12)\n",
    "ax1.set_title('Portfolio Survival Curve (Kaplan-Meier Style)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='lower left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(0, RETIREMENT_YEARS)\n",
    "ax1.set_ylim(min(survival_rates) * 100 - 2, 102)\n",
    "ax1.set_xticks(range(0, RETIREMENT_YEARS + 1, 5))\n",
    "\n",
    "# Right: Failure Rate (cumulative probability of failure)\n",
    "ax2 = axes[1]\n",
    "failure_rates = [1 - sr for sr in survival_rates]\n",
    "\n",
    "ax2.plot(years_plot, np.array(failure_rates) * 100, 'r-', linewidth=2.5, label='Cumulative Failure Rate')\n",
    "ax2.fill_between(years_plot, np.array(failure_rates) * 100, alpha=0.2, color='red')\n",
    "\n",
    "# Mark key points\n",
    "for threshold in [1, 5, 10]:\n",
    "    years_above = [y for y, fr in zip(years_plot, failure_rates) if fr * 100 >= threshold]\n",
    "    if years_above:\n",
    "        first_year = years_above[0]\n",
    "        ax2.axhline(y=threshold, color='gray', linestyle=':', alpha=0.5)\n",
    "        ax2.axvline(x=first_year, color='gray', linestyle=':', alpha=0.5)\n",
    "        ax2.scatter([first_year], [threshold], color='darkred', s=50, zorder=5)\n",
    "\n",
    "ax2.set_xlabel('Year', fontsize=12)\n",
    "ax2.set_ylabel('Cumulative Failure Rate (%)', fontsize=12)\n",
    "ax2.set_title('Cumulative Probability of Depletion', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim(0, RETIREMENT_YEARS)\n",
    "ax2.set_xticks(range(0, RETIREMENT_YEARS + 1, 5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key statistics\n",
    "print(\"--- Survival Rate at Key Years ---\")\n",
    "key_years = [5, 10, 15, 20, 25, 30]\n",
    "for year in key_years:\n",
    "    sr = survival_rates[year] * 100\n",
    "    print(f\"  Year {year:>2}: {sr:>6.2f}% survived ({100-sr:.2f}% failed)\")\n",
    "\n",
    "# Find years when key thresholds are crossed\n",
    "print(\"\\n--- Years to Reach Failure Thresholds ---\")\n",
    "for threshold in [1, 5, 10]:\n",
    "    years_above = [y for y, fr in zip(years_plot, failure_rates) if fr * 100 >= threshold]\n",
    "    if years_above:\n",
    "        print(f\"  {threshold}% failure rate reached: Year {years_above[0]}\")\n",
    "    else:\n",
    "        print(f\"  {threshold}% failure rate: Not reached in {RETIREMENT_YEARS} years\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEPLETION YEAR CDF (Cumulative Distribution Function)\n",
    "# ============================================================================\n",
    "# The CDF shows what percentage of failures occurred BY a given year.\n",
    "# Useful for understanding the concentration of failures across time.\n",
    "\n",
    "if depletion_years:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"DEPLETION YEAR CDF: Cumulative Distribution of Failures\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nThe CDF shows what percentage of all failures occurred BY each year.\")\n",
    "    print(\"This helps answer: 'Of all portfolios that failed, what % failed by year X?'\\n\")\n",
    "    \n",
    "    # Sort depletion years for CDF\n",
    "    sorted_depletion = np.sort(depletion_years)\n",
    "    n_failures = len(sorted_depletion)\n",
    "    \n",
    "    # Calculate CDF values\n",
    "    cdf_values = np.arange(1, n_failures + 1) / n_failures\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot CDF\n",
    "    ax.step(sorted_depletion, cdf_values * 100, where='post', linewidth=2.5, color='darkred',\n",
    "            label='Cumulative % of Failures')\n",
    "    ax.fill_between(sorted_depletion, cdf_values * 100, step='post', alpha=0.2, color='red')\n",
    "    \n",
    "    # Add reference lines at key percentiles\n",
    "    for pct in [25, 50, 75, 90]:\n",
    "        year_at_pct = np.percentile(depletion_years, pct)\n",
    "        ax.axhline(y=pct, color='gray', linestyle=':', alpha=0.5)\n",
    "        ax.axvline(x=year_at_pct, color='gray', linestyle=':', alpha=0.5)\n",
    "        ax.scatter([year_at_pct], [pct], color='darkblue', s=60, zorder=5)\n",
    "        ax.annotate(f'Year {year_at_pct:.0f}', \n",
    "                    xy=(year_at_pct, pct),\n",
    "                    xytext=(year_at_pct + 1, pct + 3),\n",
    "                    fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Depletion Year', fontsize=12)\n",
    "    ax.set_ylabel('Cumulative % of All Failures', fontsize=12)\n",
    "    ax.set_title('Depletion Year CDF: When Do Failures Occur?\\n'\n",
    "                 f'(Based on {n_failures:,} failed simulations)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(0, RETIREMENT_YEARS + 1)\n",
    "    ax.set_ylim(0, 105)\n",
    "    ax.set_xticks(range(0, RETIREMENT_YEARS + 1, 5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print key percentiles\n",
    "    print(\"--- Percentiles of Depletion Year ---\")\n",
    "    print(\"  (Of all portfolios that failed, what % failed by year X?)\")\n",
    "    print()\n",
    "    for pct in [10, 25, 50, 75, 90, 95]:\n",
    "        year_at_pct = np.percentile(depletion_years, pct)\n",
    "        print(f\"  {pct}% of failures occurred by year {year_at_pct:.0f}\")\n",
    "    \n",
    "    # Calculate interquartile range\n",
    "    iqr = np.percentile(depletion_years, 75) - np.percentile(depletion_years, 25)\n",
    "    print(f\"\\n  Interquartile range (IQR): {iqr:.1f} years\")\n",
    "    print(f\"  (Middle 50% of failures span {iqr:.1f} years)\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"No depletion events to analyze - all portfolios survived!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PORTFOLIO VALUE DISTRIBUTION BY YEAR (Boxplot)\n",
    "# ============================================================================\n",
    "# Boxplots show the distribution of portfolio values at key years,\n",
    "# providing a comprehensive view of the spread and outliers.\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PORTFOLIO VALUE DISTRIBUTION BY YEAR\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nBoxplots show the distribution of portfolio values at each milestone,\")\n",
    "print(\"including median, quartiles, and outliers.\\n\")\n",
    "\n",
    "# Select years for boxplot (every 5 years)\n",
    "years_for_boxplot = [0, 5, 10, 15, 20, 25, 30]\n",
    "data_for_boxplot = [portfolios[:, y] for y in years_for_boxplot]\n",
    "\n",
    "# Create visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data_for_boxplot, tick_labels=[f'Year {y}' for y in years_for_boxplot],\n",
    "                showfliers=False,  # Hide outliers for cleaner visualization\n",
    "                patch_artist=True,\n",
    "                medianprops=dict(color='darkred', linewidth=2))\n",
    "\n",
    "# Color boxes by survival rate at that year\n",
    "survival_at_years = [np.sum(portfolios[:, y] > 0) / N_SIMULATIONS for y in years_for_boxplot]\n",
    "colors = plt.cm.RdYlGn(survival_at_years)  # Red-Yellow-Green colormap\n",
    "\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "# Add zero line\n",
    "ax.axhline(y=0, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Depletion threshold')\n",
    "\n",
    "# Add initial portfolio reference\n",
    "ax.axhline(y=INITIAL_PORTFOLIO, color='blue', linestyle=':', linewidth=1.5, alpha=0.5, \n",
    "           label=f'Initial: €{INITIAL_PORTFOLIO/1e6:.0f}M')\n",
    "\n",
    "ax.set_xlabel('Retirement Year', fontsize=12)\n",
    "ax.set_ylabel('Portfolio Value (EUR)', fontsize=12)\n",
    "ax.set_title('Portfolio Value Distribution at Key Years\\n'\n",
    "             '(Box color indicates survival rate: Green=High, Red=Low)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'€{x/1e6:.1f}M' if x >= 1e6 else f'€{x/1000:.0f}k'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics for each year\n",
    "print(\"--- Summary Statistics by Year ---\")\n",
    "print(f\"{'Year':<6} {'Median':>12} {'Mean':>12} {'P5':>12} {'P95':>12} {'Survival':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for year in years_for_boxplot:\n",
    "    values = portfolios[:, year]\n",
    "    survival = np.sum(values > 0) / N_SIMULATIONS * 100\n",
    "    print(f\"{year:<6} €{np.median(values):>10,.0f} €{np.mean(values):>10,.0f} \"\n",
    "          f\"€{np.percentile(values, 5):>10,.0f} €{np.percentile(values, 95):>10,.0f} {survival:>9.1f}%\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FAN CHART: Sample Portfolio Trajectories\n",
    "# ============================================================================\n",
    "# Visualize individual portfolio paths to understand the variability\n",
    "# and identify patterns in successful vs failed scenarios.\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FAN CHART: Sample Portfolio Trajectories\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThis chart shows 200 randomly sampled portfolio trajectories.\")\n",
    "print(\"Failed portfolios (depletion) are highlighted in red.\\n\")\n",
    "\n",
    "# Sample trajectories for visualization\n",
    "np.random.seed(SEED)  # For reproducibility\n",
    "n_sample = 200\n",
    "\n",
    "# Separate failed and successful simulations\n",
    "failed_mask = portfolios[:, -1] <= 0\n",
    "failed_indices = np.where(failed_mask)[0]\n",
    "success_indices = np.where(~failed_mask)[0]\n",
    "\n",
    "# Sample proportionally (but ensure we get some failed ones if they exist)\n",
    "n_failed_sample = min(len(failed_indices), n_sample // 2)\n",
    "n_success_sample = n_sample - n_failed_sample\n",
    "\n",
    "if len(failed_indices) > 0:\n",
    "    sample_failed = np.random.choice(failed_indices, size=n_failed_sample, replace=False)\n",
    "else:\n",
    "    sample_failed = np.array([], dtype=int)\n",
    "    \n",
    "sample_success = np.random.choice(success_indices, size=min(n_success_sample, len(success_indices)), replace=False)\n",
    "\n",
    "# Create visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "years_plot = np.arange(0, RETIREMENT_YEARS + 1)\n",
    "\n",
    "# Plot successful trajectories first (green, low alpha)\n",
    "for idx in sample_success:\n",
    "    ax.plot(years_plot, portfolios[idx], color='green', alpha=0.1, linewidth=0.5)\n",
    "\n",
    "# Plot failed trajectories (red, higher alpha)\n",
    "for idx in sample_failed:\n",
    "    ax.plot(years_plot, portfolios[idx], color='red', alpha=0.4, linewidth=0.8)\n",
    "\n",
    "# Add percentile lines for reference\n",
    "for p, color, label in [(50, 'blue', 'Median'), (5, 'orange', '5th percentile'), (95, 'purple', '95th percentile')]:\n",
    "    pct_values = np.percentile(portfolios, p, axis=0)\n",
    "    ax.plot(years_plot, pct_values, color=color, linewidth=2.5, label=label, linestyle='--')\n",
    "\n",
    "# Add zero line\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=2, alpha=0.7, label='Depletion')\n",
    "\n",
    "# Add legend entries for trajectory types\n",
    "ax.plot([], [], color='green', alpha=0.5, linewidth=1, label=f'Successful ({len(success_indices):,})')\n",
    "ax.plot([], [], color='red', alpha=0.7, linewidth=1, label=f'Failed ({len(failed_indices):,})')\n",
    "\n",
    "ax.set_xlabel('Retirement Year', fontsize=12)\n",
    "ax.set_ylabel('Portfolio Value (EUR)', fontsize=12)\n",
    "ax.set_title(f'Sample Portfolio Trajectories (n={n_sample})\\n'\n",
    "             f'Red = Failed, Green = Successful',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0, RETIREMENT_YEARS)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'€{x/1e6:.1f}M' if abs(x) >= 1e6 else f'€{x/1000:.0f}k'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: worst and best performing portfolios\n",
    "print(\"--- Extreme Scenarios ---\")\n",
    "\n",
    "# Worst performing (lowest final value)\n",
    "worst_idx = np.argmin(portfolios[:, -1])\n",
    "print(f\"\\n  Worst scenario (Sim #{worst_idx}):\")\n",
    "print(f\"    Final value: €{portfolios[worst_idx, -1]:,.0f}\")\n",
    "if portfolios[worst_idx, -1] <= 0:\n",
    "    dep_year = np.where(portfolios[worst_idx] <= 0)[0][0]\n",
    "    print(f\"    Depleted in year: {dep_year}\")\n",
    "\n",
    "# Best performing (highest final value)\n",
    "best_idx = np.argmax(portfolios[:, -1])\n",
    "print(f\"\\n  Best scenario (Sim #{best_idx}):\")\n",
    "print(f\"    Final value: €{portfolios[best_idx, -1]:,.0f}\")\n",
    "print(f\"    Growth multiple: {portfolios[best_idx, -1] / INITIAL_PORTFOLIO:.1f}x initial\")\n",
    "\n",
    "# Plot extreme scenarios\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(years_plot, portfolios[worst_idx], 'r-', linewidth=2, label='Worst scenario')\n",
    "ax.plot(years_plot, portfolios[best_idx], 'g-', linewidth=2, label='Best scenario')\n",
    "ax.plot(years_plot, np.median(portfolios, axis=0), 'b--', linewidth=2, label='Median')\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle=':', linewidth=1, alpha=0.5)\n",
    "ax.axhline(y=INITIAL_PORTFOLIO, color='gray', linestyle=':', linewidth=1, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Retirement Year', fontsize=12)\n",
    "ax.set_ylabel('Portfolio Value (EUR)', fontsize=12)\n",
    "ax.set_title('Extreme Scenarios: Best vs Worst Portfolio Paths', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'€{x/1e6:.1f}M' if abs(x) >= 1e6 else f'€{x/1000:.0f}k'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Summary and Conclusions\n",
    "\n",
    "Comprehensive summary of simulation results including:\n",
    "- Portfolio configuration\n",
    "- Historical data period used\n",
    "- Success rate and percentile outcomes\n",
    "- Failure statistics (if any)\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Success Rate**: Indicates robustness of 4% withdrawal rate for this portfolio\n",
    "2. **Percentiles**: Show range of possible outcomes\n",
    "3. **Sensitivity**: Identifies maximum sustainable withdrawal rate\n",
    "4. **Failures**: Understand downside risks and scenarios\n",
    "\n",
    "### Important Caveat: No Tax Assumption\n",
    "This analysis assumes **no capital gains tax** is applied on withdrawals. In practice:\n",
    "- Italian investors face a 26% capital gains tax on financial gains\n",
    "- This would reduce the effective withdrawal rate or require higher gross withdrawals\n",
    "- Tax-advantaged accounts (where available) would more closely match these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MONTE CARLO SIMULATION SUMMARY (BLOCK BOOTSTRAP)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Simulation parameters:\")\n",
    "print(f\"  - Initial portfolio: €{INITIAL_PORTFOLIO:,}\")\n",
    "print(f\"  - Withdrawal rate: {ANNUAL_WITHDRAWAL_RATE:.1%}\")\n",
    "print(f\"  - Retirement duration: {RETIREMENT_YEARS} years\")\n",
    "print(f\"  - Number of simulations: {N_SIMULATIONS:,}\")\n",
    "print(f\"  - Block size: {BLOCK_SIZE_MONTHS} months\")\n",
    "print(f\"  - Capital gains tax: None (tax-free withdrawals)\")\n",
    "print(f\"\\nPortfolio composition:\")\n",
    "for asset, weight in PORTFOLIO_WEIGHTS.items():\n",
    "    print(f\"  - {asset}: {weight:.1%}\")\n",
    "print(f\"\\nInflation series: {INFLATION_SERIES}\")\n",
    "print(f\"\\nHistorical data period:\")\n",
    "print(f\"  - From: {returns_df['date'].min()}\")\n",
    "print(f\"  - To: {returns_df['date'].max()}\")\n",
    "print(f\"  - Total days: {len(returns_df):,}\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  - Success rate: {success_rate:.2%}\")\n",
    "print(f\"  - Median final value: €{np.median(portfolios[:, -1]):,.0f}\")\n",
    "print(f\"  - P5 final value: €{np.percentile(portfolios[:, -1], 5):,.0f}\")\n",
    "print(f\"  - P95 final value: €{np.percentile(portfolios[:, -1], 95):,.0f}\")\n",
    "if depletion_years:\n",
    "    print(f\"  - Failed simulations: {len(depletion_years)} ({len(depletion_years)/N_SIMULATIONS:.1%})\")\n",
    "    print(f\"  - Median depletion year: {np.median(depletion_years):.0f}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n⚠️  NOTE: This simulation assumes NO capital gains tax on withdrawals.\")\n",
    "print(\"    In taxed scenarios, effective withdrawal rates would be lower.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
