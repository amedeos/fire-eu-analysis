{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HICP MIDX - Extract Italy and Euro Area Data\n",
        "\n",
        "This notebook extracts HICP (Harmonised Index of Consumer Prices) data for Italy and Euro Area from the compressed Eurostat file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input file: data/eurostat/prc_hicp_midx_linear.csv.gz\n",
            "Output file: data/eurostat/hicp_it_eu.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Check that the file exists\n",
        "input_file = 'data/eurostat/prc_hicp_midx_linear.csv.gz'\n",
        "output_file = 'data/eurostat/hicp_it_eu.csv'\n",
        "\n",
        "if not os.path.exists(input_file):\n",
        "    raise FileNotFoundError(f\"File not found: {input_file}\")\n",
        "\n",
        "print(f\"Input file: {input_file}\")\n",
        "print(f\"Output file: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Countries to extract: ['Italy', 'Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)']\n",
            "COICOP filter: All-items HICP\n"
          ]
        }
      ],
      "source": [
        "# Define the countries to extract\n",
        "target_countries = [\n",
        "    'Italy',\n",
        "    'Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)'\n",
        "]\n",
        "\n",
        "# Define the coicop filter\n",
        "target_coicop = 'All-items HICP'\n",
        "\n",
        "print(f\"Countries to extract: {target_countries}\")\n",
        "print(f\"COICOP filter: {target_coicop}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading file in chunks...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n",
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n",
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n",
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 10 chunks...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n",
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n",
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n",
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 20 chunks...\n",
            "Processed 30 chunks...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n",
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 40 chunks...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 50 chunks...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 60 chunks...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_48/3951373012.py:7: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 70 chunks...\n",
            "Total chunks processed: 77\n"
          ]
        }
      ],
      "source": [
        "# Read the file efficiently using chunks\n",
        "# This avoids loading the entire file into memory\n",
        "chunks = []\n",
        "chunk_size = 100000  # Read 100k rows at a time\n",
        "\n",
        "print(\"Reading file in chunks...\")\n",
        "for i, chunk in enumerate(pd.read_csv(input_file, compression='gzip', chunksize=chunk_size, low_memory=False)):\n",
        "    # Filter by countries and coicop\n",
        "    filtered_chunk = chunk[\n",
        "        (chunk['geo'].isin(target_countries)) & \n",
        "        (chunk['coicop'] == target_coicop)\n",
        "    ]\n",
        "    if not filtered_chunk.empty:\n",
        "        chunks.append(filtered_chunk)\n",
        "    \n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"Processed {i + 1} chunks...\")\n",
        "\n",
        "print(f\"Total chunks processed: {i + 1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted rows: 2148\n",
            "\n",
            "First extracted data:\n",
            "                   DATAFLOW        LAST UPDATE     freq             unit  \\\n",
            "0  ESTAT:PRC_HICP_MIDX(1.0)  19/11/25 11:00:00  Monthly  Index, 2005=100   \n",
            "1  ESTAT:PRC_HICP_MIDX(1.0)  19/11/25 11:00:00  Monthly  Index, 2005=100   \n",
            "2  ESTAT:PRC_HICP_MIDX(1.0)  19/11/25 11:00:00  Monthly  Index, 2005=100   \n",
            "3  ESTAT:PRC_HICP_MIDX(1.0)  19/11/25 11:00:00  Monthly  Index, 2005=100   \n",
            "4  ESTAT:PRC_HICP_MIDX(1.0)  19/11/25 11:00:00  Monthly  Index, 2005=100   \n",
            "\n",
            "           coicop                                                geo  \\\n",
            "0  All-items HICP  Euro area (EA11-1999, EA12-2001, EA13-2007, EA...   \n",
            "1  All-items HICP  Euro area (EA11-1999, EA12-2001, EA13-2007, EA...   \n",
            "2  All-items HICP  Euro area (EA11-1999, EA12-2001, EA13-2007, EA...   \n",
            "3  All-items HICP  Euro area (EA11-1999, EA12-2001, EA13-2007, EA...   \n",
            "4  All-items HICP  Euro area (EA11-1999, EA12-2001, EA13-2007, EA...   \n",
            "\n",
            "  TIME_PERIOD  OBS_VALUE OBS_FLAG CONF_STATUS  \n",
            "0     1996-01      83.70      NaN         NaN  \n",
            "1     1996-02      84.08      NaN         NaN  \n",
            "2     1996-03      84.38      NaN         NaN  \n",
            "3     1996-04      84.52      NaN         NaN  \n",
            "4     1996-05      84.71      NaN         NaN  \n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2148 entries, 0 to 2147\n",
            "Data columns (total 10 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   DATAFLOW     2148 non-null   object \n",
            " 1   LAST UPDATE  2148 non-null   object \n",
            " 2   freq         2148 non-null   object \n",
            " 3   unit         2148 non-null   object \n",
            " 4   coicop       2148 non-null   object \n",
            " 5   geo          2148 non-null   object \n",
            " 6   TIME_PERIOD  2148 non-null   object \n",
            " 7   OBS_VALUE    2148 non-null   float64\n",
            " 8   OBS_FLAG     0 non-null      object \n",
            " 9   CONF_STATUS  0 non-null      object \n",
            "dtypes: float64(1), object(9)\n",
            "memory usage: 167.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Combine all filtered chunks\n",
        "if chunks:\n",
        "    df_filtered = pd.concat(chunks, ignore_index=True)\n",
        "    print(f\"Extracted rows: {len(df_filtered)}\")\n",
        "    print(f\"\\nFirst extracted data:\")\n",
        "    print(df_filtered.head())\n",
        "    print(f\"\\nDataset info:\")\n",
        "    print(df_filtered.info())\n",
        "else:\n",
        "    print(\"No data found for the specified countries!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Countries present in extracted data:\n",
            "geo\n",
            "Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)    1074\n",
            "Italy                                                                                                            1074\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Verify the countries present in the extracted data\n",
        "if chunks:\n",
        "    print(\"Countries present in extracted data:\")\n",
        "    print(df_filtered['geo'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "File saved successfully: data/eurostat/hicp_it_eu.csv\n",
            "Dimensions: 2148 rows, 10 columns\n"
          ]
        }
      ],
      "source": [
        "# Save the filtered file\n",
        "if chunks:\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "    \n",
        "    # Save the CSV\n",
        "    df_filtered.to_csv(output_file, index=False)\n",
        "    print(f\"\\nFile saved successfully: {output_file}\")\n",
        "    print(f\"Dimensions: {len(df_filtered)} rows, {len(df_filtered.columns)} columns\")\n",
        "else:\n",
        "    print(\"No data to save!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
