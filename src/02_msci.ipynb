{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MSCI Indices - Download and Fill Missing Days\n",
        "\n",
        "This notebook downloads MSCI index data from the GitHub repository and fills missing days using backward fill (bfill).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# Change to project root directory\n",
        "# Find the project root by looking for the 'data' directory\n",
        "current_dir = os.getcwd()\n",
        "while not os.path.exists(os.path.join(current_dir, 'data')):\n",
        "    parent_dir = os.path.dirname(current_dir)\n",
        "    if parent_dir == current_dir:\n",
        "        # Reached filesystem root without finding 'data' directory\n",
        "        raise FileNotFoundError(\"Could not find project root directory (looking for 'data' folder)\")\n",
        "    current_dir = parent_dir\n",
        "\n",
        "os.chdir(current_dir)\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "\n",
        "# GitHub repository base URL\n",
        "github_base_url = \"https://raw.githubusercontent.com/amedeos/Stock-Indexes-Historical-Data/main\"\n",
        "\n",
        "# Define the files to download\n",
        "files_to_download = {\n",
        "    'ACWI': 'DAILY/NET/EUR/ALL-COUNTRY-DM-EM/Region/NONE/NONE/STANDARD-LARGE-MID-CAP/ACWI.csv',\n",
        "    'WORLD': 'DAILY/NET/EUR/DEVELOPED-MARKETS-DM/Region/NONE/NONE/STANDARD-LARGE-MID-CAP/WORLD.csv',\n",
        "    'ITALY': 'DAILY/NET/EUR/DEVELOPED-MARKETS-DM/Country/NONE/NONE/STANDARD-LARGE-MID-CAP/ITALY.csv'\n",
        "}\n",
        "\n",
        "# Output directory\n",
        "output_dir = 'data/msci'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"\\nFiles to download:\")\n",
        "for name, path in files_to_download.items():\n",
        "    print(f\"  {name}: {path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and process each file\n",
        "for index_name, file_path in files_to_download.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing {index_name}...\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Construct the full URL\n",
        "    file_url = f\"{github_base_url}/{file_path}\"\n",
        "    print(f\"Downloading from: {file_url}\")\n",
        "    \n",
        "    # Download the file\n",
        "    try:\n",
        "        response = requests.get(file_url)\n",
        "        response.raise_for_status()\n",
        "        print(f\"Download successful (size: {len(response.content)} bytes)\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading file: {e}\")\n",
        "        continue\n",
        "    \n",
        "    # Read CSV into pandas\n",
        "    df = pd.read_csv(StringIO(response.text))\n",
        "    print(f\"\\nOriginal data shape: {df.shape}\")\n",
        "    print(f\"Columns: {df.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df.head())\n",
        "    \n",
        "    # Identify the date column (common names: Date, DATE, date, TIME_PERIOD, etc.)\n",
        "    date_col = None\n",
        "    for col in df.columns:\n",
        "        if col.lower() in ['date', 'time_period', 'time', 'timestamp']:\n",
        "            date_col = col\n",
        "            break\n",
        "    \n",
        "    if date_col is None:\n",
        "        print(f\"Warning: Could not identify date column. Assuming first column is date.\")\n",
        "        date_col = df.columns[0]\n",
        "    \n",
        "    print(f\"\\nUsing '{date_col}' as date column\")\n",
        "    \n",
        "    # Convert date column to datetime\n",
        "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
        "    \n",
        "    # Check for missing dates\n",
        "    print(f\"\\nDate range: {df[date_col].min()} to {df[date_col].max()}\")\n",
        "    print(f\"Total rows: {len(df)}\")\n",
        "    \n",
        "    # Create a complete date range (daily)\n",
        "    date_range = pd.date_range(start=df[date_col].min(), end=df[date_col].max(), freq='D')\n",
        "    print(f\"Expected daily rows: {len(date_range)}\")\n",
        "    print(f\"Missing days: {len(date_range) - len(df)}\")\n",
        "    \n",
        "    # Set date as index\n",
        "    df_indexed = df.set_index(date_col)\n",
        "    \n",
        "    # Reindex to include all days\n",
        "    df_complete = df_indexed.reindex(date_range)\n",
        "    \n",
        "    # Apply backward fill (bfill) to fill missing days\n",
        "    df_filled = df_complete.bfill()\n",
        "    \n",
        "    # Reset index to have date as a column again\n",
        "    df_filled = df_filled.reset_index()\n",
        "    df_filled = df_filled.rename(columns={'index': date_col})\n",
        "    \n",
        "    print(f\"\\nAfter filling missing days:\")\n",
        "    print(f\"Total rows: {len(df_filled)}\")\n",
        "    print(f\"Missing values per column:\")\n",
        "    print(df_filled.isnull().sum())\n",
        "    \n",
        "    # Save to output directory\n",
        "    output_file = os.path.join(output_dir, f\"{index_name}.csv\")\n",
        "    df_filled.to_csv(output_file, index=False)\n",
        "    print(f\"\\nSaved to: {output_file}\")\n",
        "    print(f\"Final shape: {df_filled.shape}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
